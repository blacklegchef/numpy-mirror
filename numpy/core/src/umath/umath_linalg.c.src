/* -*- c -*- */

/*
 *****************************************************************************
 **                            INCLUDES                                     **
 *****************************************************************************
 */
#define NPY_NO_DEPRECATED_API NPY_API_VERSION

#include "Python.h"
#include "numpy/arrayobject.h"
#include "numpy/ufuncobject.h"

#include "npy_pycompat.h"

#include "npy_config.h"

#ifndef CBLAS_HEADER
#define CBLAS_HEADER "cblas.h"
#endif

#ifndef CLAPACK_HEADER
#define CLAPACK_HEADER "clapack.h"
#endif

#include CBLAS_HEADER
#include CLAPACK_HEADER

#include <stddef.h>
#include <stdio.h>
#include <assert.h>


#define TRACE do { printf ("%s:%d:%s\n", __FILE__, __LINE__, __FUNCTION__); } while (0)


const char* umath_linalg_version_string = "0.1.0";
/*
 *****************************************************************************
 *                    BLAS/LAPACK calling macros                             *
 *****************************************************************************
 */
#define CBLAS(FUNC) cblas_ ## FUNC
#define LAPACK_T(FUNC) printf("Calling LAPACK ( " # FUNC " )\n"); FUNC ## _
#define LAPACK(FUNC) FUNC ## _

/* TODO: Fix this properly */
typedef __CLPK_integer fortran_int;
typedef __CLPK_real    fortran_real;
typedef __CLPK_doublereal fortran_doublereal;
typedef __CLPK_complex fortran_complex;
typedef __CLPK_doublecomplex fortran_doublecomplex;

#if 1
#  define INTERNAL
#else
#  define INTERNAL static
#endif

/*
 *****************************************************************************
 **                      Some handy constants                               **
 *****************************************************************************
 */

static const char* umath_linalg_module_name =  "umath_linalg";

typedef union {
    fortran_complex f;
    npy_cfloat npy;
    float array[2];
} COMPLEX_t;

typedef union {
    fortran_doublecomplex f;
    npy_cdouble npy;
    double array[2];
} DOUBLECOMPLEX_t;

static const float s_one       =  1.0f;
static const float s_zero      =  0.0f;
static const float s_minus_one = -1.0f;
static const float s_ninf      = -1.0f/0.0f; 
static const double d_one       =  1.0;
static const double d_zero      =  0.0;
static const double d_minus_one = -1.0;
static const double d_ninf      = -1.0/0.0;
static const COMPLEX_t c_one       = { {  1.0f, 0.0f } };
static const COMPLEX_t c_zero      = { {  0.0f, 0.0f } };
static const COMPLEX_t c_minus_one = { { -1.0f, 0.0f } };
static const COMPLEX_t c_ninf      = { { -1.0f/0.0f, 0.0f } };
static const DOUBLECOMPLEX_t z_one       = {{  1.0,  0.0 }};
static const DOUBLECOMPLEX_t z_zero      = {{  0.0,  0.0 }};
static const DOUBLECOMPLEX_t z_minus_one = {{ -1.0,  0.0 }};
static const DOUBLECOMPLEX_t z_ninf      = {{ -1.0/0.0, 0.0 }};


/*
 *****************************************************************************
 **               Structs used for data rearrangement                       **
 *****************************************************************************
 */


/* this struct contains information about how to linearize in a local buffer
   a matrix so that it can be used by blas functions.
   All strides are specified in number of elements (similar to what blas expects)

   dst_row_strides: number of elements between different row. Matrix is considered
                    row-major
   dst_column_strides: number of elements between differnt columns in the
                    destination buffer
   rows: number of rows of the matrix
   columns: number of columns of the matrix
   src_row_strides: strides needed to access the next row in the source matrix
   src_column_strides: strides needed to access the next column in the source
                       matrix
 */
typedef struct linearize_data_struct
{
  size_t     rows;
  size_t     columns;
  ptrdiff_t  row_strides;
  ptrdiff_t  column_strides;
} LINEARIZE_DATA_t;

static inline void
init_linearize_data(LINEARIZE_DATA_t *lin_data, 
                    int rows, 
                    int columns, 
                    ptrdiff_t row_strides, 
                    ptrdiff_t column_strides)
{
    lin_data->rows = rows;
    lin_data->columns = columns;
    lin_data->row_strides = row_strides;
    lin_data->column_strides = column_strides;
}

static inline void
dump_ufunc_object(PyUFuncObject* ufunc)
{
    printf("\n\n%s '%s' (%d input(s), %d output(s), %d specialization(s).\n",
           ufunc->core_enabled? "generalized ufunc" : "scalar ufunc",
           ufunc->name, ufunc->nin, ufunc->nout, ufunc->ntypes);
    if (ufunc->core_enabled) {
        int arg;
        int dim;
        printf("\t%s (%d dimension(s) detected).\n",
               ufunc->core_signature, ufunc->core_num_dim_ix);

        for (arg = 0; arg < ufunc->nargs; arg++){
            int * arg_dim_ix = ufunc->core_dim_ixs + ufunc->core_offsets[arg];
            printf("\t\targ %d (%s) has %d dimension(s): (",
                   arg, arg < ufunc->nin? "INPUT" : "OUTPUT", ufunc->core_num_dims[arg]);
            for (dim = 0; dim < ufunc->core_num_dims[arg]; dim ++) {
                printf(" %d", arg_dim_ix[dim]);
            }
            printf(" )\n");
        }
    }
}

static inline void
dump_linearize_data(const char* name, const LINEARIZE_DATA_t* params)
{
    printf("\n\t%s rows: %zd columns: %zd"
           "\n\t\trow_strides: %td column_strides: %td"
           "\n", name, params->rows, params->columns,
           params->row_strides, params->column_strides);
}

static inline void
print_FLOAT(npy_float s)
{
    printf(" %8.4f", s);
}
static inline void
print_DOUBLE(npy_double d)
{
    printf(" %10.6f", d);
}
static inline void
print_CFLOAT(npy_cfloat c)
{
    float* c_parts = (float*)&c;
    printf(" %8.4f + %8.4fj", c_parts[0], c_parts[1]);
}
static inline void
print_CDOUBLE(npy_cdouble z)
{
    double* z_parts = (double*)&z;
    printf(" %8.4f + %8.4fj", z_parts[0], z_parts[1]);
}

/**begin repeat
   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #typ=npy_float,npy_double,npy_cfloat,npy_cdouble#
 */
static inline void
dump_@TYPE@_matrix(const char* name, size_t rows, size_t columns, const @typ@* ptr)
{
    size_t i,j;

    printf("\n%s %p (%zd, %zd)\n", name, ptr, rows, columns);
    for (i=0; i<rows; i++)
    {
        printf("(");
        for (j=0; j<columns; j++)
        {
            print_@TYPE@(*ptr++);
        }
        printf(" )\n");
    }
}
/**end repeat**/


/*
 *****************************************************************************
 **                            Basics                                       **
 *****************************************************************************
 */

#define INIT_OUTER_LOOP_1       \
    npy_intp dN = *dimensions++;\
    npy_intp N_;                \
    npy_intp s0 = *steps++;

#define INIT_OUTER_LOOP_2       \
    INIT_OUTER_LOOP_1           \
    npy_intp s1 = *steps++;

#define INIT_OUTER_LOOP_3       \
    INIT_OUTER_LOOP_2           \
    npy_intp s2 = *steps++;

#define INIT_OUTER_LOOP_4       \
    INIT_OUTER_LOOP_3           \
    npy_intp s3 = *steps++;

#define BEGIN_OUTER_LOOP_2      \
    for (N_ = 0; N_ < dN; N_++, args[0] += s0, args[1] += s1) {

#define BEGIN_OUTER_LOOP_3      \
    for (N_ = 0; N_ < dN; N_++, args[0] += s0, args[1] += s1, args[2] += s2) {

#define BEGIN_OUTER_LOOP_4      \
    for (N_ = 0; N_ < dN; N_++, args[0] += s0, args[1] += s1, args[2] += s2, args[3] += s3) {

#define END_OUTER_LOOP  }

static void inline
update_pointers(uint8_t** bases, ptrdiff_t* offsets, size_t count)
{
    size_t i;
    for (i=0; i < count; ++i) {
        bases[i] += offsets[i];
    }
}

/*
 *****************************************************************************
 **                             HELPER FUNCS                                **
 *****************************************************************************
 */

             /* rearranging of 2D matrices using blas */

/**begin repeat

    #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
    #typ=npy_float,npy_double,npy_cfloat,npy_cdouble# 
    #cblas_type=s,d,c,z#
 */
static inline void *
linearize_@TYPE@_matrix(void *dst_in, void *src_in,const LINEARIZE_DATA_t* data)
{
    @typ@ *src = (@typ@ *) src_in;
    @typ@ *dst = (@typ@ *) dst_in;

    if (dst) {
        int i;
        @typ@* rv = dst;
        for (i=0; i< data->rows; i++) {
            CBLAS(@cblas_type@copy)((fortran_int)data->columns,
                                    src, (fortran_int)(data->column_strides/sizeof(@typ@)),
                                    dst, (fortran_int)1);
            src += data->row_strides/sizeof(@typ@);
            dst += data->columns;
        } 
        return rv;
    } else {
        return src;
    }
}

static inline void *
delinearize_@TYPE@_matrix(void *dst_in, void *src_in,const LINEARIZE_DATA_t* data)
{
    @typ@ *src = (@typ@ *) src_in;
    @typ@ *dst = (@typ@ *) dst_in;

    if (src) {
        int i;
        @typ@ *rv = src;
        for (i=0; i < data->rows; i++) {
            CBLAS(@cblas_type@copy)((fortran_int)data->columns,
                                    src, (fortran_int)1,
                                    dst, (fortran_int)(data->column_strides/sizeof(@typ@)));
            src += data->columns;
            dst += data->row_strides/sizeof(@typ@);
        }

        return rv;
    } else {
        return src;
    }
}
/**end repeat**/

               /* identity square matrix generation */
/**begin repeat
   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #typ=float,double,COMPLEX_t,DOUBLECOMPLEX_t#
   #cblas_type=s,d,c,z#
 */
static inline void
identity_@TYPE@_matrix(void *ptr, size_t n)
{
    size_t i;
    @typ@ *matrix = (@typ@*) ptr;
    memset(matrix, 0, n*n*sizeof(@typ@)); /* all zeros 0.0 is stored as all 0 */

    for (i = 0; i < n; ++i)
    {
        *matrix = @cblas_type@_one;
        matrix += n+1;
    }
}
/**end repeat**/

         /* lower/upper triangular matrix using blas (in place) */
/**begin repeat

   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #typ=float,double,COMPLEX_t,DOUBLECOMPLEX_t#
   #cblas_type=s,d,c,z#
 */
static inline void
tril_@TYPE@_matrix(void *ptr, size_t n)
{
    size_t i,j;
    @typ@ *matrix = (@typ@*)ptr;
    matrix++;
    for (i = n-1; i > 0; --i) {
        for (j = 0; j < i; ++j) {
            *matrix = @cblas_type@_zero;
        }
        matrix += n + 1;
    }
}

static inline void
triu_@TYPE@_matrix(void *ptr, size_t n)
{
    size_t i,j;
    @typ@ *matrix = (@typ@*)ptr;
    matrix += n;
    for (i=1; i < n; ++i) {
        for (j=0; j<i; ++j) {
            matrix[j] = @cblas_type@_zero;
        }
        matrix += n;
    }
}
/**end repeat**/
/*
 *****************************************************************************
 **                             UFUNC LOOPS                                 **
 *****************************************************************************
 */

/**begin repeat

   #TYPE=FLOAT,DOUBLE#
   #typ=npy_float, npy_double#
   #cblas_dot=cblas_sdot, cblas_ddot# 

*/

static inline void 
@TYPE@_inner1d_blas(char **args, npy_intp* dimensions, npy_intp * steps)
{
    INIT_OUTER_LOOP_3
    const size_t sot = sizeof(@typ@);

    int dim = (int) dimensions[0];
    int is1 = (int)(steps[0]/sot), is2 = (int)(steps[1]/sot);

    BEGIN_OUTER_LOOP_3
        @typ@ * ip1 = (@typ@*)args[0], *ip2 = (@typ@*)args[1];
        *(@typ@*)(args[2]) = @cblas_dot@(dim, ip1, is1, ip2, is2);
    END_OUTER_LOOP
}

static inline void 
@TYPE@_inner1d_std(char **args, npy_intp* dimensions, npy_intp * steps)
{
    INIT_OUTER_LOOP_3
    npy_intp di = dimensions[0];
    npy_intp i;
    npy_intp is1=steps[0], is2=steps[1];
    BEGIN_OUTER_LOOP_3
        char *ip1=args[0], *ip2=args[1], *op=args[2];
    @typ@ sum = 0;
        for (i = 0; i < di; i++) {
            sum += (*(@typ@ *)ip1) * (*(@typ@ *)ip2);
            ip1 += is1;
            ip2 += is2;
        }
        *(@typ@ *)op = sum;
    END_OUTER_LOOP
}

INTERNAL void
@TYPE@_inner1d(char **args, npy_intp *dimensions, npy_intp *steps,
               void *NPY_UNUSED(func))
{
    const size_t sot = sizeof(@typ@);
    /* 
     * use blas if the stride is a multiple of datatype size in the inputs
     * it should be the common case 
     */

    if ((0 == (steps[3] % sot)) &&
        (0 == (steps[4] % sot))) {
        /* use blas */
        @TYPE@_inner1d_blas(args, dimensions, steps);
    } else {
        /* use standard version */
        @TYPE@_inner1d_std(args, dimensions, steps);
    }
}

/**end repeat**/


/* -------------------------------------------------------------------------- */

/**begin repeat

   #TYPE=FLOAT,DOUBLE#
   #typ=npy_float, npy_double# 

*/

/*
 *  This implements the function
 *        out[n] = sum_i { in1[n, i] * in2[n, i] * in3[n, i] }.
 */

INTERNAL void
@TYPE@_innerwt(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    INIT_OUTER_LOOP_4
    npy_intp di = dimensions[0];
    npy_intp i;
    npy_intp is1=steps[0], is2=steps[1], is3=steps[2];
    BEGIN_OUTER_LOOP_4
        char *ip1=args[0], *ip2=args[1], *ip3=args[2], *op=args[3];
        @typ@ sum = 0;
        for (i = 0; i < di; i++) {
            sum += (*(@typ@ *)ip1) * (*(@typ@ *)ip2) * (*(@typ@ *)ip3);
            ip1 += is1;
            ip2 += is2;
            ip3 += is3;
        }
        *(@typ@ *)op = sum;
    END_OUTER_LOOP
}

/**end repeat**/


/* -------------------------------------------------------------------------- */
                        /* Matrix Multiply */

typedef struct gemm_params_struct
{
    fortran_int m,n,k; // note there is a relationship between this and lin_data rows
                 // & columns but the actual relationship is dependent on trans.
    fortran_int strides[3]; // strides to use in gemm call
    void *buff[3];  // memory buff for the operand to use in blas call
    LINEARIZE_DATA_t lin_data[3];
    void *allocated_data;
    int   trans[2]; // use transpose
} GEMM_PARAMS_t;

static inline void
dump_gemm_params(const GEMM_PARAMS_t* params)
{
    printf("\n\ngemm_params: src1: %s transposed src2: %s transposed"
           "\n\tM: %d N: %d K: %d",
           params->trans[0] == CblasNoTrans? "NOT" : "",
           params->trans[1] == CblasNoTrans? "NOT" : "",
           (int)params->m, (int)params->n, (int)params->k);
    dump_linearize_data("src1", &params->lin_data[0]);
    dump_linearize_data("src2", &params->lin_data[1]);
    dump_linearize_data("dst", &params->lin_data[2]);
}

static inline void
init_gemm_params(GEMM_PARAMS_t *params,
                 char** args,
                 npy_intp *dimensions,
                 npy_intp* steps,
                 size_t size_of_type)
{
    int i, m, n, k;

    m = (int) dimensions[0];
    k = (int) dimensions[1];
    n = (int) dimensions[2];

    for (i = 0; i < sizeof(params->trans)/sizeof(params->trans[0]); i++)
        params->trans[i] = CblasNoTrans;

    params->m = m;
    params->n = n;
    params->k = k;

    // this should be initialized later when it is known whether we are doing it
    // in-place or in a tmp buffer.
    for (i = 0 ; i < sizeof(params->strides)/sizeof(params->strides[0]); i++)
       params->strides[i] = 0;

    init_linearize_data(&params->lin_data[0], m, k, steps[0], steps[1]);
    init_linearize_data(&params->lin_data[1], k, n, steps[2], steps[3]);
    init_linearize_data(&params->lin_data[2], m, n, steps[4], steps[5]);

    /* compute size and reserve if needed local buffers */
    {
        size_t buff_size[3];
        size_t total_buff_size, offset;

        for (i = 0; i < 3; i++) {
            if (params->lin_data[i].column_strides == size_of_type) {
                /* do it *in-place* */
                buff_size[i] = 0;
                params->strides[i] = (fortran_int)(steps[i*2] / size_of_type);
            } else {
                /* buffer needed to linearize */
                int rows = (int)params->lin_data[i].rows;
                int columns = (int)params->lin_data[i].columns;
                buff_size[i] = rows * columns * size_of_type;
                params->strides[i] = columns;
            }
        }
        
        total_buff_size = buff_size[0] + buff_size[1] + buff_size[2];
        if (total_buff_size) {
            params->allocated_data = (uint8_t*)malloc(total_buff_size);
        } else {
            params->allocated_data = NULL;
        }
        
        offset = 0;
        for (i=0; i<3; i++) {
            if (buff_size[i] == 0) {
                /* inplace */ 
                params->buff[i] = NULL;
            } else {
                /* an intermediate copy will be needed */
                params->buff[i] = (void*)(params->allocated_data + offset);
                offset += buff_size[i];
            }
        }

        assert(total_buff_size == offset);
    }
}

static inline void
release_gemm_params(GEMM_PARAMS_t * params)
{
    free(params->allocated_data);
    params->allocated_data = NULL;
}


/**begin repeat

   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #typ=npy_float,npy_double,npy_cfloat,npy_cdouble#
   #one=1.0f,1.0,c_one.array,z_one.array#
   #zero=0.0f,0.0,c_zero.array,z_one.array#
   #cblas_type=s,d,c,z#
*/

INTERNAL void
@TYPE@_matrix_multiply(char **args, 
                       npy_intp *dimensions, 
                       npy_intp *steps, 
                       void *NPY_UNUSED(func))
{
    /* 
     * everything is setup in a way that makes things work. BLAS gemm can be
     * be called without rearranging nor using weird stuff, as matrices are
     * in the expected way in memory.
     * This is just a loop calling blas.
     */
    GEMM_PARAMS_t params;
    INIT_OUTER_LOOP_3

    init_gemm_params(&params, args, dimensions, steps, sizeof(@typ@));

    BEGIN_OUTER_LOOP_3
        /* just call the appropriate multiply and update pointers */
        @typ@ *src1 = linearize_@TYPE@_matrix(params.buff[0],
                                              args[0],
                                              &params.lin_data[0]);
        @typ@ *src2 = linearize_@TYPE@_matrix(params.buff[1],
                                              args[1],
                                              &params.lin_data[1]);
        @typ@ *dst = params.buff[2] ? params.buff[2] : (@typ@ *) args[2];

        /* linearize source operands if needed */
        CBLAS(@cblas_type@gemm)(CblasRowMajor,
                                params.trans[0], params.trans[1],
                                params.m, params.n, params.k, 
                                @one@, // alpha
                                src1, params.strides[0],
                                src2, params.strides[1],
                                @zero@, // beta
                                dst, params.strides[2]);
        
        delinearize_@TYPE@_matrix(args[2],
                                  params.buff[2],
                                  &params.lin_data[2]);
    END_OUTER_LOOP

    release_gemm_params(&params);
}
/**end repeat**/


/* -------------------------------------------------------------------------- */
                          /* Determinants */

/**begin repeat

   #TYPE=FLOAT,DOUBLE#
   #typ=npy_float, npy_double#
   #log_func=npy_logf,npy_log#
   #exp_func=npy_expf,npy_exp#
   #zero=0.0f,0.0#
*/
static inline @typ@
@TYPE@_mult(@typ@ op1, @typ@ op2)
{
    return op1 * op2;
}

static inline void
@TYPE@_slogdet_from_factored_diagonal(@typ@* src,
                                      fortran_int m,
                                      @typ@ *sign,
                                      @typ@ *logdet)
{
    @typ@ acc_sign = *sign;
    @typ@ acc_logdet = @zero@;
    int i;
    for (i = 0; i < m; i++) {
        @typ@ abs_element = *src;
        if (abs_element < @zero@) {
            acc_sign = -acc_sign;
            abs_element = -abs_element;
        }

        acc_logdet += @log_func@(abs_element);
        src += m+1;
    }

    *sign = acc_sign;
    *logdet = acc_logdet;
}

static inline @typ@
@TYPE@_det_from_slogdet(@typ@ sign, @typ@ logdet)
{
    @typ@ result = sign * @exp_func@(logdet);
    return result;
}

/**end repeat**/

/**begin repeat

   #TYPE=CFLOAT,CDOUBLE#
   #typ=npy_cfloat, npy_cdouble#
   #basetyp=npy_float, npy_double#
   #abs_func=npy_cabsf, npy_cabs#
   #log_func=npy_logf, npy_log#
   #exp_func=npy_expf, npy_exp#
   #zero=0.0f,0.0#
*/
#define RE(COMPLEX) (((@basetyp@*)(&COMPLEX))[0])
#define IM(COMPLEX) (((@basetyp@*)(&COMPLEX))[1])

static inline @typ@
@TYPE@_mult(@typ@ op1, @typ@ op2)
{
    @typ@ rv;

    RE(rv) = RE(op1)*RE(op2) - IM(op1)*IM(op2);
    IM(rv) = RE(op1)*IM(op2) - IM(op1)*RE(op2);

    return rv;
}


static inline void
@TYPE@_slogdet_from_factored_diagonal(@typ@* src,
                                      fortran_int m,
                                      @typ@ *sign, 
                                      @basetyp@ *logdet)
{
    int i;
    @typ@ sign_acc = *sign;
    @basetyp@ logdet_acc = @zero@;

    for (i = 0; i < m; i++)
    {
        @basetyp@ abs_element = @abs_func@(*src);
        @typ@ sign_element;
        RE(sign_element) = RE(*src) / abs_element;
        IM(sign_element) = IM(*src) / abs_element;

        sign_acc = @TYPE@_mult(sign_acc, sign_element);
        logdet_acc += @log_func@(abs_element);
        src += m + 1;
    }

    *sign = sign_acc;
    *logdet = logdet_acc;
}

static inline @typ@
@TYPE@_det_from_slogdet(@typ@ sign, @basetyp@ logdet)
{
    @typ@ tmp;
    RE(tmp) = @exp_func@(logdet);
    IM(tmp) = @zero@;
    return @TYPE@_mult(sign, tmp);
}
#undef RE
#undef IM

/**end repeat**/

/* As in the linalg package, the determinant is computed via LU factorization
 * using LAPACK.
 * slogdet computes sign + log(determinant).
 * det computes sign * exp(slogdet).
 */ 
/**begin repeat

   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #typ=npy_float,npy_double,npy_cfloat,npy_cdouble#
   #basetyp=npy_float,npy_double,npy_float,npy_double#
   #cblas_type=s,d,c,z#
*/

static inline void
@TYPE@_slogdet_single_element(fortran_int m, 
                              void* src, 
                              fortran_int* pivots, 
                              @typ@ *sign, 
                              @basetyp@ *logdet)
{
    fortran_int info = 0;
    int i;
    /* note: done in place */
    LAPACK(@cblas_type@getrf)(&m, &m, (void *)src, &m, pivots, &info);
    
    if (info == 0)
    {
        int change_sign = 0;
        /* note: fortran uses 1 based indexing */
        for (i=0; i < m; i++)
        {
            change_sign += (pivots[i] != (i+1));
        }
    
        memcpy(sign, (change_sign % 2)? &@cblas_type@_minus_one : &@cblas_type@_one, sizeof(*sign));
        @TYPE@_slogdet_from_factored_diagonal(src, m, sign, logdet);
    } else {
        memcpy(sign, &@cblas_type@_zero, sizeof(*sign));
        memcpy(logdet, &@cblas_type@_ninf, sizeof(*logdet));
    }
    
}

INTERNAL void
@TYPE@_slogdet(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    fortran_int m;
    uint8_t* tmp_buff = NULL;
    size_t matrix_size;
    size_t pivot_size;
    /* notes:
     *   matrix will need to be copied always, as factorization in lapack is made inplace
     *   matrix will need to be in column-major order, as expected by lapack code (fortran)
     *   always a square matrix
     *   need to allocate memory for both, matrix_buffer and pivot buffer
     */
    INIT_OUTER_LOOP_3
    m = (fortran_int) dimensions[0];
    matrix_size = m*m*sizeof(@typ@);
    pivot_size = m*sizeof(fortran_int); 
    tmp_buff = (uint8_t *)malloc(matrix_size + pivot_size); 

    if (tmp_buff)
    {
        LINEARIZE_DATA_t lin_data;
        /* swapped steps to get matrix in FORTRAN order */
        init_linearize_data(&lin_data, m, m, (ptrdiff_t)steps[1], (ptrdiff_t)steps[0]);
        BEGIN_OUTER_LOOP_3
            linearize_@TYPE@_matrix(tmp_buff, args[0], &lin_data);
            @TYPE@_slogdet_single_element(m,
                                          (void*)tmp_buff,
                                          (fortran_int*)(tmp_buff+matrix_size),
                                          (@typ@*)args[1],
                                          (@basetyp@*)args[2]); 
        END_OUTER_LOOP

        free(tmp_buff);
    }
}

INTERNAL void
@TYPE@_det(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    fortran_int m;
    uint8_t* tmp_buff;
    size_t matrix_size;
    size_t pivot_size;
    /* notes:
     *   matrix will need to be copied always, as factorization in lapack is made inplace
     *   matrix will need to be in column-major order, as expected by lapack code (fortran)
     *   always a square matrix
     *   need to allocate memory for both, matrix_buffer and pivot buffer
     */
    INIT_OUTER_LOOP_2
    m = (fortran_int) dimensions[0];
    matrix_size = m*m*sizeof(@typ@);
    pivot_size = m*sizeof(fortran_int); 
    tmp_buff = (uint8_t *)malloc(matrix_size + pivot_size); 

    if (tmp_buff)
    {
        LINEARIZE_DATA_t lin_data;
        @typ@ sign;
        @basetyp@ logdet;
        /* swapped steps to get matrix in FORTRAN order */
        init_linearize_data(&lin_data, m, m, (ptrdiff_t)steps[1], (ptrdiff_t)steps[0]);

        BEGIN_OUTER_LOOP_2
            linearize_@TYPE@_matrix(tmp_buff, args[0], &lin_data);
            @TYPE@_slogdet_single_element(m,
                                          (void*)tmp_buff,
                                          (fortran_int*)(tmp_buff+matrix_size),
                                          &sign,
                                          &logdet);
            *(@typ@ *)args[1] = @TYPE@_det_from_slogdet(sign, logdet);
        END_OUTER_LOOP

        free(tmp_buff);
    }
}
/**end repeat**/

/* -------------------------------------------------------------------------- */
                          /* Eigh family */

typedef struct eigh_params_struct {
    void *A;     /* matrix */
    void *W;     /* eigenvalue vector */
    void *WORK;  /* main work buffer */
    void *RWORK; /* secondary work buffer (for complex versions) */
    void *IWORK; 
    fortran_int N;
    fortran_int LWORK;
    fortran_int LRWORK;
    fortran_int LIWORK;
    char JOBZ;
    char UPLO;
} EIGH_PARAMS_t;

/**begin repeat

   #TYPE=FLOAT,DOUBLE#
   #typ=npy_float,npy_double#
   #ftyp=fortran_real,fortran_doublereal#
   #lapack_func=ssyevd,dsyevd#
*/

/*
 * Initialize the parameters to use in for the lapack function _syevd
 * Handles buffer allocation
 */
static inline int
init_@lapack_func@(EIGH_PARAMS_t* params, char JOBZ, char UPLO,
                   fortran_int N)
{
    uint8_t *mem_buff = NULL;
    uint8_t *mem_buff2 = NULL;
    @typ@ query_work_size;
    fortran_int query_iwork_size;
    fortran_int lwork  = -1;
    fortran_int liwork = -1;
    fortran_int info;
    uint8_t *a, *w, *work, *iwork;
    size_t alloc_size = N*(N+1)*sizeof(@typ@);

    mem_buff = malloc(alloc_size);
  
    if (!mem_buff)
        goto error;
    a = mem_buff;
    w = mem_buff + N*N*sizeof(@typ@);
    LAPACK(@lapack_func@)(&JOBZ, &UPLO, &N, 
                          (@ftyp@*)a, &N, (@ftyp@*)w,
                          &query_work_size, &lwork,
                          &query_iwork_size, &liwork,
                          &info);

    if (info != 0)
        goto error;

    lwork = (fortran_int)query_work_size;
    liwork = query_iwork_size;
    mem_buff2 = malloc(lwork*sizeof(@typ@) + liwork*sizeof(fortran_int));
    if (!mem_buff2)
        goto error;

    work = mem_buff2;
    iwork = mem_buff2 + lwork*sizeof(@typ@);

    params->A = a;
    params->W = w;
    params->WORK = mem_buff2;
    params->RWORK = NULL; /* unused */
    params->IWORK = iwork;
    params->N = N;
    params->LWORK = lwork;
    params->LRWORK = 0; /* unused */
    params->LIWORK = liwork;
    params->JOBZ = JOBZ;
    params->UPLO = UPLO;
    
    return 1;

 error:
    /* something failed */
    memset(params, 0, sizeof(*params));
    free(mem_buff2);
    free(mem_buff);

    return 0;
}

static inline fortran_int
call_@lapack_func@(EIGH_PARAMS_t *params)
{
    fortran_int rv;
    LAPACK(@lapack_func@)(&params->JOBZ, &params->UPLO, &params->N,
                          params->A, &params->N, params->W, 
                          params->WORK, &params->LWORK,
                          params->IWORK, &params->LIWORK,
                          &rv);
    return rv;
}
/**end repeat**/

/**begin repeat

   #TYPE=CFLOAT,CDOUBLE#
   #typ=npy_cfloat,npy_cdouble#
   #basetyp=npy_float,npy_double#
   #ftyp=fortran_complex,fortran_doublecomplex#
   #fbasetyp=fortran_real,fortran_doublereal#
   #lapack_func=cheevd,zheevd#
*/
/*
 * Initialize the parameters to use in for the lapack function _heev
 * Handles buffer allocation
 */
static inline int
init_@lapack_func@(EIGH_PARAMS_t *params, char JOBZ, char UPLO,
                   fortran_int N)
{
    uint8_t *mem_buff = NULL;
    uint8_t *mem_buff2 = NULL;
    @ftyp@ query_work_size;
    @fbasetyp@ query_rwork_size;
    fortran_int query_iwork_size;
    fortran_int lwork = -1;
    fortran_int lrwork = -1;
    fortran_int liwork = -1;
    uint8_t *a, *w, *work, *rwork, *iwork;
    fortran_int info;

    mem_buff = malloc(N*N*sizeof(@typ@)+N*sizeof(@basetyp@));
    if (!mem_buff) 
        goto error;
    a = mem_buff;
    w = mem_buff+N*N*sizeof(@typ@);
    
    LAPACK(@lapack_func@)(&JOBZ, &UPLO, &N, 
                          (@ftyp@*)a, &N, (@fbasetyp@*)w,
                          &query_work_size, &lwork,
                          &query_rwork_size, &lrwork,
                          &query_iwork_size, &liwork,
                          &info);
    if (info != 0)
        goto error;

    lwork = (fortran_int)*(@fbasetyp@*)&query_work_size;
    lrwork = (fortran_int)query_rwork_size;
    liwork = query_iwork_size;

    mem_buff2 = malloc(lwork*sizeof(@typ@) + lrwork*sizeof(@basetyp@) + liwork*sizeof(fortran_int));
    if (!mem_buff2)
        goto error;
    work = mem_buff2;
    rwork = work + lwork*sizeof(@typ@);
    iwork = rwork + lrwork*sizeof(@basetyp@);

    params->A = a;
    params->W = w;
    params->WORK = work;
    params->RWORK = rwork;
    params->IWORK = iwork;
    params->N = N;
    params->LWORK = lwork;
    params->LRWORK = lrwork;
    params->LIWORK = liwork;
    params->JOBZ = JOBZ;
    params->UPLO = UPLO;
    
    return 1;

    /* something failed */
error:
    memset(params, 0, sizeof(*params));
    free(mem_buff2);
    free(mem_buff);

    return 0;
}

static inline fortran_int
call_@lapack_func@(EIGH_PARAMS_t *params)
{
    fortran_int rv;
    LAPACK(@lapack_func@)(&params->JOBZ, &params->UPLO, &params->N,
                          params->A, &params->N, params->W, 
                          params->WORK, &params->LWORK,
                          params->RWORK, &params->LRWORK,
                          params->IWORK, &params->LIWORK,
                          &rv);
    return rv;
}
/**end repeat**/

/**begin repeat
   
   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #BASETYPE=FLOAT,DOUBLE,FLOAT,DOUBLE#
   #typ=npy_float,npy_double,npy_cfloat,npy_cdouble#
   #basetyp=npy_float,npy_double,npy_float,npy_double#
   #lapack_func=ssyevd,dsyevd,cheevd,zheevd#
  **/ 
/*
 * (M,M)->(M,)(M,M)
 * dimensions[1] -> M
 * args[0] -> A[in]
 * args[1] -> W
 * args[2] -> A[out]
 */

static inline void
release_@lapack_func@(EIGH_PARAMS_t *params)
{
    /* allocated memory in A and WORK */
    free(params->A);
    free(params->WORK);
    memset(params, 0, sizeof(*params));
}


static inline void
@TYPE@_eigh_wrapper(char JOBZ, char UPLO, char**args, npy_intp* dimensions, npy_intp* steps)
{
    ptrdiff_t outer_steps[3];
    size_t iter;
    size_t outer_dim = *dimensions++;
    size_t op_count = (JOBZ=='N')?2:3;
    EIGH_PARAMS_t eigh_params;

    for (iter=0; iter < op_count; ++iter) {
        outer_steps[iter] = (ptrdiff_t) steps[iter];
    }
    steps += op_count;

    if (init_@lapack_func@(&eigh_params, JOBZ, UPLO, (fortran_int)dimensions[0])) {
        LINEARIZE_DATA_t matrix_in_ld;
        LINEARIZE_DATA_t eigenvectors_out_ld;
        LINEARIZE_DATA_t eigenvalues_out_ld;

        init_linearize_data(&matrix_in_ld,
                            eigh_params.N, eigh_params.N,
                            steps[1], steps[0]);
        init_linearize_data(&eigenvalues_out_ld,
                            1, eigh_params.N,
                            0, steps[2]);
        if ('V' == eigh_params.JOBZ) {
            init_linearize_data(&eigenvectors_out_ld, 
                                eigh_params.N, eigh_params.N,
                                steps[4], steps[3]);
        }

        for (iter = 0; iter < outer_dim; ++iter) {
            /* copy the matrix in */
            linearize_@TYPE@_matrix(eigh_params.A, args[0], &matrix_in_ld);
            call_@lapack_func@(&eigh_params);
            delinearize_@BASETYPE@_matrix(args[1], eigh_params.W, &eigenvalues_out_ld);
            
            if ('V' == eigh_params.JOBZ) {
                delinearize_@TYPE@_matrix(args[2], eigh_params.A, &eigenvectors_out_ld);
            }
            update_pointers((uint8_t**)args, outer_steps, op_count);
        }

        release_@lapack_func@(&eigh_params);
    }
}
/**end repeat**/

/**begin repeat
   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
 */
static void
@TYPE@_eighlo(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    @TYPE@_eigh_wrapper('V', 'L', args, dimensions, steps);
}

static void
@TYPE@_eighup(char **args, npy_intp *dimensions, npy_intp *steps, void* NPY_UNUSED(func))
{
    @TYPE@_eigh_wrapper('V', 'U', args, dimensions, steps);
}

static void
@TYPE@_eigvalshlo(char **args, npy_intp *dimensions, npy_intp *steps, void* NPY_UNUSED(func))
{
    @TYPE@_eigh_wrapper('N', 'L', args, dimensions, steps);
}

static void
@TYPE@_eigvalshup(char **args, npy_intp *dimensions, npy_intp *steps, void* NPY_UNUSED(func))
{
    @TYPE@_eigh_wrapper('N', 'U', args, dimensions, steps);
}
/**end repeat**/

/* -------------------------------------------------------------------------- */
                  /* Solve family (includes inv) */

typedef struct gesv_params_struct 
{
    void *A; /* A is (N,N) of base type */
    void *B; /* B is (N,NRHS) of base type */
    fortran_int * IPIV; /* IPIV is (N) */
    
    fortran_int N;
    fortran_int NRHS;
    fortran_int LDA;
    fortran_int LDB;
} GESV_PARAMS_t;
/**begin repeat

   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #typ=npy_float,npy_double,npy_cfloat,npy_cdouble#
   #ftyp=fortran_real,fortran_doublereal,fortran_complex,fortran_doublecomplex#
   #lapack_func=sgesv,dgesv,cgesv,zgesv#

*/
/*
 * Initialize the parameters to use in for the lapack function _heev
 * Handles buffer allocation
 */
static inline int
init_@lapack_func@(GESV_PARAMS_t *params, fortran_int N, fortran_int NRHS) 
{
    uint8_t *mem_buff = NULL;
    uint8_t *a, *b, *ipiv;
    mem_buff = malloc(N*N*sizeof(@ftyp@) + N*NRHS*sizeof(@ftyp@) + N*sizeof(fortran_int));
    if (!mem_buff)
        goto error;
    a = mem_buff;
    b = a + N*N*sizeof(@ftyp@); 
    ipiv = b + N*NRHS*sizeof(@ftyp@);

    params->A = a;
    params->B = b;
    params->IPIV = (fortran_int*)ipiv;
    params->N = N;
    params->NRHS = NRHS;
    params->LDA = N;
    params->LDB = N;

    return 1;
 error:
    free(mem_buff);
    memset(params, 0, sizeof(*params));

    return 0;
}

static inline void
release_@lapack_func@(GESV_PARAMS_t *params)
{
    /* memory block base is in A */
    free(params->A);
    memset(params, 0, sizeof(*params));
}

static inline fortran_int
call_@lapack_func@(GESV_PARAMS_t *params)
{
    fortran_int rv;
    LAPACK(@lapack_func@)(&params->N, &params->NRHS,
                          params->A, &params->LDA,
                          params->IPIV,
                          params->B, &params->LDB,
                          &rv);
    return rv;
}

static void
@TYPE@_solve(char **args, npy_intp *dimensions, npy_intp *steps,
             void *NPY_UNUSED(func))
{
    GESV_PARAMS_t params;
    fortran_int n, nrhs;
    INIT_OUTER_LOOP_3

    n = (fortran_int)dimensions[0];
    nrhs = (fortran_int)dimensions[2];
    if (init_@lapack_func@(&params, n, nrhs)) {
        LINEARIZE_DATA_t a_in, b_in, r_out;

        init_linearize_data(&a_in, n, n, steps[1], steps[0]);
        init_linearize_data(&b_in, nrhs, n, steps[3], steps[2]);
        init_linearize_data(&r_out, nrhs, n, steps[5], steps[4]);

        BEGIN_OUTER_LOOP_3
            linearize_@TYPE@_matrix(params.A, args[0], &a_in);
            linearize_@TYPE@_matrix(params.B, args[1], &b_in);
            call_@lapack_func@(&params);
            delinearize_@TYPE@_matrix(args[2], params.B, &r_out);
        END_OUTER_LOOP

        release_@lapack_func@(&params);
    }
}

static void
@TYPE@_solve1(char **args, npy_intp *dimensions, npy_intp *steps,
              void *NPY_UNUSED(func))
{
    GESV_PARAMS_t params;
    fortran_int n;
    INIT_OUTER_LOOP_3

    n = (fortran_int)dimensions[0];
    if (init_@lapack_func@(&params, n, 1)) {
        LINEARIZE_DATA_t a_in, b_in, r_out;
        init_linearize_data(&a_in, n, n, steps[1], steps[0]);
        init_linearize_data(&b_in, 1, n, 1, steps[2]);
        init_linearize_data(&r_out, 1, n, 1, steps[3]);

        BEGIN_OUTER_LOOP_3
            linearize_@TYPE@_matrix(params.A, args[0], &a_in);
            linearize_@TYPE@_matrix(params.B, args[1], &b_in);
            call_@lapack_func@(&params);
            delinearize_@TYPE@_matrix(args[2], params.B, &r_out);
        END_OUTER_LOOP

        release_@lapack_func@(&params);
    }
}

static void
@TYPE@_inv(char **args, npy_intp *dimensions, npy_intp *steps,
           void *NPY_UNUSED(func))
{
    GESV_PARAMS_t params;
    fortran_int n;
    INIT_OUTER_LOOP_2

    n = (fortran_int)dimensions[0];
    if (init_@lapack_func@(&params, n, n)) {
        LINEARIZE_DATA_t a_in, r_out;
        init_linearize_data(&a_in, n, n, steps[1], steps[0]);
        init_linearize_data(&r_out, n, n, steps[3], steps[2]);

        BEGIN_OUTER_LOOP_2
            linearize_@TYPE@_matrix(params.A, args[0], &a_in);
            identity_@TYPE@_matrix(params.B, n);
            call_@lapack_func@(&params);
            delinearize_@TYPE@_matrix(args[1], params.B, &r_out);
        END_OUTER_LOOP

        release_@lapack_func@(&params);
    }  
}
/**end repeat**/


/* -------------------------------------------------------------------------- */
                     /* Cholesky decomposition */

typedef struct potr_params_struct
{
    void *A;
    fortran_int N;
    fortran_int LDA;
    char UPLO;
} POTR_PARAMS_t;

/**begin repeat

   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #ftyp=fortran_real, fortran_doublereal, fortran_complex, fortran_doublecomplex#
   #lapack_func=spotrf,dpotrf,cpotrf,zpotrf#
 */

static inline int
init_@lapack_func@(POTR_PARAMS_t *params, fortran_int N)
{
    uint8_t* mem_buff = NULL;
    uint8_t* a;

    mem_buff = malloc(N*N*sizeof(@ftyp@));
    if (!mem_buff)
        goto error;

    a = mem_buff;

    params->A = a;
    params->N = N;
    params->LDA = N;
    params->UPLO = 'L';

    return 1;
 error:
    free(mem_buff);
    memset(params, 0, sizeof(*params));

    return 0;
}

static inline void
release_@lapack_func@(POTR_PARAMS_t *params)
{
    /* memory block base in A */
    free(params->A);
    memset(params, 0, sizeof(*params));
}

static inline fortran_int
call_@lapack_func@(POTR_PARAMS_t *params)
{
    fortran_int rv;
    LAPACK(@lapack_func@)(&params->UPLO, 
                          &params->N, params->A, &params->LDA,
                          &rv);
    return rv;
}

static void
@TYPE@_cholesky(char **args, npy_intp *dimensions, npy_intp *steps,
                void *NPY_UNUSED(func))
{
    POTR_PARAMS_t params;
    fortran_int n;
    INIT_OUTER_LOOP_2

    n = (fortran_int)dimensions[0];
    if (init_@lapack_func@(&params, n))
    {
        LINEARIZE_DATA_t a_in, r_out;
        init_linearize_data(&a_in, n, n, steps[1], steps[0]);
        init_linearize_data(&r_out, n, n, steps[3], steps[2]);
        BEGIN_OUTER_LOOP_2
            linearize_@TYPE@_matrix(params.A, args[0], &a_in);
            call_@lapack_func@(&params);
            triu_@TYPE@_matrix(params.A, params.N);
            delinearize_@TYPE@_matrix(args[1], params.A, &r_out);
        END_OUTER_LOOP
        release_@lapack_func@(&params);
    }
}



/**end repeat**/

/* -------------------------------------------------------------------------- */
                          /* eig family  */

typedef struct geev_params_struct {
    void *A;
    void *WR; /* RWORK in complex versions, REAL W buffer for _geev where _ is s, d */
    void *WI;
    void *VLR; /* REAL VL buffers for _geev where _ is s, d */
    void *VRR; /* REAL VR buffers for _geev hwere _ is s, d */
    void *WORK;
    void *W;  /* final w */
    void *VL; /* final vl */
    void *VR; /* final vr */

    fortran_int N;
    fortran_int LDA;
    fortran_int LDVL;
    fortran_int LDVR;
    fortran_int LWORK;

    char JOBVL;
    char JOBVR;
} GEEV_PARAMS_t;

static inline void
dump_geev_params(const char *name, GEEV_PARAMS_t* params)
{
    printf ("\n%s\n"
            "\t%10s: %p\n" "\t%10s: %p\n" "\t%10s: %p\n" "\t%10s: %p\n"
            "\t%10s: %p\n" "\t%10s: %p\n" "\t%10s: %p\n" "\t%10s: %p\n"
            "\t%10s: %p\n"
            "\t%10s: %d\n" "\t%10s: %d\n" "\t%10s: %d\n" "\t%10s: %d\n"
            "\t%10s: %d\n"
            "\t%10s: %c\n" "\t%10s: %c\n",
            name,
            "A", params->A, "WR", params->WR, "WI", params->WI, "VLR", params->VLR,
            "VRR", params->VRR, "WORK", params->WORK, "W", params->W, "VL", params->VL,
            "VR", params->VR,
            "N", (int)params->N, "LDA", (int)params->LDA, "LDVL", (int)params->LDVL, "LDVR", (int)params->LDVR,
            "LWORK", (int)params->LWORK,
            "JOBVL", params->JOBVL, "JOBVR", params->JOBVR);
}

/**begin repeat
   #TYPE=FLOAT,DOUBLE#
   #typ=float,double#
   #complextyp=COMPLEX_t,DOUBLECOMPLEX_t#
   #lapack_func=sgeev,dgeev#
   #zero=0.0f,0.0#
*/
static inline int
init_@lapack_func@(GEEV_PARAMS_t *params, char jobvl, char jobvr, fortran_int n)
{
    uint8_t *mem_buff=NULL;
    uint8_t *mem_buff2=NULL;
    uint8_t *a, *wr, *wi, *vlr, *vrr, *work, *w, *vl, *vr;
    size_t a_size = n*n*sizeof(@typ@);
    size_t wr_size = n*sizeof(@typ@);
    size_t wi_size = n*sizeof(@typ@);
    size_t vlr_size = jobvl=='V' ? n*n*sizeof(@typ@) : 0;
    size_t vrr_size = jobvr=='V' ? n*n*sizeof(@typ@) : 0;
    size_t w_size = wr_size*2;
    size_t vl_size = vlr_size*2;
    size_t vr_size = vrr_size*2;
    size_t work_count = 0;
    @typ@ work_size_query;
    fortran_int do_size_query = -1;
    fortran_int rv;

    /* allocate data for known sizes (all but work) */
    mem_buff = malloc(a_size + wr_size + wi_size + 
                      vlr_size + vrr_size +
                      w_size + vl_size + vr_size);
    if (!mem_buff)
        goto error;

    a = mem_buff;
    wr = a + a_size;
    wi = wr + wr_size;
    vlr = wi + wi_size;
    vrr = vlr + vlr_size;
    w = vrr + vrr_size;
    vl = w + w_size;
    vr = vl + vl_size;
    LAPACK(@lapack_func@)(&jobvl, &jobvr, &n, 
                          (void *)a, &n, (void *)wr, (void *)wi, 
                          (void *)vl, &n, (void *)vr, &n, 
                          &work_size_query, &do_size_query,
                          &rv);

    if (0 != rv)
        goto error;

    work_count = (size_t)work_size_query;
    mem_buff2 = malloc(work_count*sizeof(@typ@));
    if (!mem_buff2)
        goto error;
    work = mem_buff2;

    params->A = a;
    params->WR = wr;
    params->WI = wi;
    params->VLR = vlr;
    params->VRR = vrr;
    params->WORK = work;
    params->W = w;
    params->VL = vl;
    params->VR = vr;
    params->N = n;
    params->LDA = n;
    params->LDVL = n;
    params->LDVR = n;
    params->LWORK = (fortran_int)work_count; 
    params->JOBVL = jobvl;
    params->JOBVR = jobvr;

    return 1;
 error:
    free(mem_buff2);
    free(mem_buff);
    memset(params, 0, sizeof(*params));

    return 0;
}

static inline fortran_int
call_@lapack_func@(GEEV_PARAMS_t* params)
{
    fortran_int rv;
    LAPACK(@lapack_func@)(&params->JOBVL, &params->JOBVR, 
                          &params->N, params->A, &params->LDA,
                          params->WR, params->WI,
                          params->VLR, &params->LDVL,
                          params->VRR, &params->LDVR,
                          params->WORK, &params->LWORK,
                          &rv);
    return rv;
}


static inline void
mk_@TYPE@_complex_array_from_real(@complextyp@ *c, const @typ@ *re, size_t n)
{
    size_t iter;
    for (iter = 0; iter < n; ++iter) {
        c[iter].array[0] = re[iter];
        c[iter].array[1] = @zero@;
    }
}

static inline void
mk_@TYPE@_complex_array(@complextyp@ *c, const @typ@ *re, const @typ@ *im, size_t n)
{
    size_t iter;
    for (iter = 0; iter < n; ++iter) {
        c[iter].array[0] = re[iter];
        c[iter].array[1] = im[iter];
    }
}

static inline void
mk_@TYPE@_complex_array_conjugate_pair(@complextyp@ *c, const @typ@ *r, size_t n)
{
    size_t iter;
    for (iter = 0; iter < n; ++iter) {
        @typ@ re = r[iter];
        @typ@ im = r[iter+n];
        c[iter].array[0] = re;
        c[iter].array[1] = im;
        c[iter+n].array[0] = re;
        c[iter+n].array[1] = -im;
    }
}

/*
 * make the complex eigenvectors from the real array produced by sgeev/zgeev.
 * c is the array where the results will be left.
 * r is the source array of reals produced by sgeev/zgeev
 * i is the eigenvalue imaginary part produced by sgeev/zgeev
 * n is so that the order of the matrix is n by n
 */
static inline void
mk_@lapack_func@_complex_eigenvectors(@complextyp@ *c, const @typ@ *r, const @typ@ *i, size_t n)
{
    size_t iter = 0;
    while (iter < n)
    {
        if (i[iter] ==  @zero@) {
            /* eigenvalue was real, eigenvectors as well...  */
            mk_@TYPE@_complex_array_from_real(c, r, n);
            c += n;
            r += n;
            iter ++;
        } else {
            /* eigenvalue was complex, generate a pair of eigenvectors */
            mk_@TYPE@_complex_array_conjugate_pair(c, r, n);
            c += 2*n;
            r += 2*n;
            iter += 2;
        }
    }
}

static inline void
process_@lapack_func@_results(GEEV_PARAMS_t *params)
{
    /* REAL versions of geev need the results to be translated
     * into complex versions. This is the way to deal with imaginary
     * results. In our gufuncs we will always return complex arrays!
     */
    mk_@TYPE@_complex_array(params->W, params->WR, params->WI, params->N);

    /* handle the eigenvectors */
    if ('V' == params->JOBVL) {
        mk_@lapack_func@_complex_eigenvectors(params->VL, params->VLR,
                                              params->WI, params->N);
    }
    if ('V' == params->JOBVR) {
        mk_@lapack_func@_complex_eigenvectors(params->VR, params->VRR,
                                              params->WI, params->N);
    }
}

/**end repeat**/
/**begin repeat
   #TYPE=CFLOAT,CDOUBLE#
   #typ=COMPLEX_t,DOUBLECOMPLEX_t#
   #ftyp=fortran_complex,fortran_doublecomplex#
   #realtyp=float,double#
   #lapack_func=cgeev,zgeev#
 */
static inline int
init_@lapack_func@(GEEV_PARAMS_t* params, char jobvl, char jobvr, fortran_int n)
{
    uint8_t *mem_buff = NULL;
    uint8_t *mem_buff2 = NULL;
    uint8_t *a, *w, *vl, *vr, *work, *rwork;
    size_t a_size = n*n*sizeof(@typ@);
    size_t w_size = n*sizeof(@typ@);
    size_t vl_size = jobvl=='V'? n*sizeof(@typ@) : 0;
    size_t vr_size = jobvr=='V'? n*sizeof(@typ@) : 0;
    size_t rwork_size = 2*n*sizeof(@realtyp@);
    size_t work_count = 0;
    @typ@ work_size_query;
    fortran_int do_size_query = -1;
    fortran_int rv;

    mem_buff = malloc(a_size + w_size + vl_size + vr_size + rwork_size);
    if (!mem_buff)
        goto error;

    a = mem_buff;
    w = a + a_size;
    vl = w + w_size;
    vr = vl + vl_size;
    rwork = vr + vr_size;

    LAPACK(@lapack_func@)(&jobvl, &jobvr, &n,
                          (void *)a, &n, (void *)w, 
                          (void *)vl, &n, (void *)vr, &n, 
                          (void *)&work_size_query, &do_size_query,
                          (void *)rwork,
                          &rv);
    if (0 != rv)
        goto error;

    work_count = (size_t) work_size_query.array[0];
    mem_buff2 = malloc(work_count*sizeof(@typ@));
    if (!mem_buff2)
        goto error;
    work = mem_buff2;
   
    params->A = a;
    params->WR = rwork;
    params->WI = NULL;
    params->VLR = NULL;
    params->VRR = NULL;
    params->VL = vl;
    params->VR = vr;
    params->WORK = work;
    params->N = n;
    params->LDA = n;
    params->LDVL = n;
    params->LDVR = n;
    params->LWORK = (fortran_int)work_count; 
    params->JOBVL = jobvl;
    params->JOBVR = jobvr;
    
    return 1;
 error:
    free(mem_buff2);
    free(mem_buff);
    memset(params, 0, sizeof(*params));

    return 0;
}

static inline fortran_int
call_@lapack_func@(GEEV_PARAMS_t* params)
{
    fortran_int rv;

    LAPACK(@lapack_func@)(&params->JOBVL, &params->JOBVR, 
                          &params->N, params->A, &params->LDA,
                          params->W,
                          params->VL, &params->LDVL,
                          params->VR, &params->LDVR,
                          params->WORK, &params->LWORK,
                          params->WR, /* actually RWORK */
                          &rv);

    return rv;
}

static inline void
process_@lapack_func@_results(GEEV_PARAMS_t *NPY_UNUSED(params))
{
    /* nothing to do here, complex versions are ready to copy out */
}
/**end repeat**/



/**begin repeat
   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #COMPLEXTYPE=CFLOAT,CDOUBLE,CFLOAT,CDOUBLE#
   #ftype=fortran_real,fortran_doublereal,fortran_complex,fortran_doublecomplex#
   #lapack_func=sgeev,dgeev,cgeev,zgeev#
 */

static inline void
release_@lapack_func@(GEEV_PARAMS_t *params)
{
    free(params->WORK);
    free(params->A);
    memset(params, 0, sizeof(*params));
}

static inline void
@TYPE@_eig_wrapper(char JOBVL, char JOBVR, char**args, npy_intp* dimensions, npy_intp* steps)
{
    ptrdiff_t outer_steps[4];
    size_t iter;
    size_t outer_dim = *dimensions++;
    size_t op_count = 2;
    GEEV_PARAMS_t geev_params;

    op_count += 'V'==JOBVL?1:0;
    op_count += 'V'==JOBVR?1:0;

    for (iter=0; iter < op_count; ++iter) {
        outer_steps[iter] = (ptrdiff_t) steps[iter];
    }
    steps += op_count;

    if (init_@lapack_func@(&geev_params, JOBVL, JOBVR, (fortran_int)dimensions[0])) {
        LINEARIZE_DATA_t a_in;
        LINEARIZE_DATA_t w_out;
        LINEARIZE_DATA_t vl_out;
        LINEARIZE_DATA_t vr_out;


        init_linearize_data(&a_in,
                            geev_params.N, geev_params.N,
                            steps[1], steps[0]);
        steps += 2;
        init_linearize_data(&w_out,
                            1, geev_params.N,
                            0, steps[0]);
        steps += 1;
        if ('V' == geev_params.JOBVL) {
            init_linearize_data(&vl_out, 
                                geev_params.N, geev_params.N,
                                steps[1], steps[0]);
            steps += 2;
        }

        if ('V' == geev_params.JOBVR) {
            init_linearize_data(&vr_out,
                                geev_params.N, geev_params.N,
                                steps[1], steps[0]);
        }
        
        for (iter = 0; iter < outer_dim; ++iter) {
            char **arg_iter = args;
            /* copy the matrix in */
            linearize_@TYPE@_matrix(geev_params.A, *arg_iter++, &a_in);

            call_@lapack_func@(&geev_params);
            process_@lapack_func@_results(&geev_params);

            delinearize_@COMPLEXTYPE@_matrix(*arg_iter++, geev_params.W, &w_out);
            if ('V' == geev_params.JOBVL)
                delinearize_@COMPLEXTYPE@_matrix(*arg_iter++, geev_params.VL, &vl_out);
            if ('V' == geev_params.JOBVR)
                delinearize_@COMPLEXTYPE@_matrix(*arg_iter++, geev_params.VR, &vr_out);

            update_pointers((uint8_t**)args, outer_steps, op_count);
        }

        release_@lapack_func@(&geev_params);
    }
}

static void
@TYPE@_eig(char **args, npy_intp *dimensions, npy_intp *steps,
           void *NPY_UNUSED(func))
{
    @TYPE@_eig_wrapper('N', 'V', args, dimensions, steps);
}

static void
@TYPE@_eigvals(char **args, npy_intp *dimensions, npy_intp *steps,
           void *NPY_UNUSED(func))
{
    @TYPE@_eig_wrapper('N', 'N', args, dimensions, steps);
}

/**end repeat**/


/* -------------------------------------------------------------------------- */
                 /* singular value decomposition  */

typedef struct gesdd_params_struct
{
    void *A;
    void *S;
    void *U;
    void *VT;
    void *WORK;
    void *RWORK;
    void *IWORK;

    fortran_int M;
    fortran_int N;
    fortran_int LDA;
    fortran_int LDU;
    fortran_int LDVT;
    fortran_int LWORK; 
    char JOBZ;
} GESDD_PARAMS_t;


static inline void
dump_gesdd_params(const char *name, GESDD_PARAMS_t *params)
{
    printf("\n%s:\n"
           "%14s: %18p\n" "%14s: %18p\n" "%14s: %18p\n" "%14s: %18p\n"
           "%14s: %18p\n" "%14s: %18p\n" "%14s: %18p\n"
           "%14s: %18d\n" "%14s: %18d\n" "%14s: %18d\n" "%14s: %18d\n"
           "%14s: %18d\n" "%14s: %18d\n"
           "%14s: %15c'%c'\n",
           name,
           "A", params->A, "S", params->S, "U", params->U, "VT", params->VT,
           "WORK", params->WORK, "RWORK", params->RWORK, "IWORK", params->IWORK,
           "M", (int)params->M, "N", (int)params->N, "LDA", (int)params->LDA, "LDU", (int)params->LDU,
           "LDVT", (int)params->LDVT, "LWORK", (int)params->LWORK, "JOBZ", ' ',params->JOBZ);

}

static inline int 
compute_urows_vtcolumns(char jobz,
                        fortran_int m, fortran_int n,
                        fortran_int *urows, fortran_int *vtcolumns)
{
    fortran_int min_m_n = m<n?m:n;
    switch(jobz)
    {
    case 'N':
        *urows = 0;
        *vtcolumns = 0;
        break;
    case 'A':
        *urows = m;
        *vtcolumns = n;
        break;
    case 'S':
        {
            *urows = min_m_n;
            *vtcolumns = min_m_n;
        }
        break;
    default:
        return 0;
    }

    return 1;
}

/**begin repeat
   #TYPE=FLOAT,DOUBLE#
   #lapack_func=sgesdd,dgesdd#
   #ftyp=fortran_real,fortran_doublereal#
 */

static inline int
init_@lapack_func@(GESDD_PARAMS_t *params, char jobz, fortran_int m, fortran_int n)
{
    uint8_t *mem_buff = NULL;
    uint8_t *mem_buff2 = NULL;
    uint8_t *a, *s, *u, *vt, *work, *iwork;
    size_t a_size = (size_t)m*(size_t)n*sizeof(@ftyp@);
    fortran_int min_m_n = m<n?m:n;
    size_t s_size = ((size_t)min_m_n)*sizeof(@ftyp@);
    fortran_int  u_row_count, vt_column_count;
    size_t u_size, vt_size;
    fortran_int work_count;
    size_t work_size;
    size_t iwork_size = 8*((size_t)min_m_n)*sizeof(fortran_int);

    if (!compute_urows_vtcolumns(jobz, m, n, &u_row_count, &vt_column_count))
        goto error;

    u_size = ((size_t)u_row_count)*m*sizeof(@ftyp@);
    vt_size = n*((size_t)vt_column_count)*sizeof(@ftyp@);

    mem_buff = malloc(a_size + s_size + u_size + vt_size + iwork_size);

    if (!mem_buff)
        goto error;

    a = mem_buff;
    s = a + a_size;
    u = s + s_size;
    vt = u + u_size;
    iwork = vt + vt_size;

    /* fix vt_column_count so that it is a valid lapack parameter (0 is not) */
    vt_column_count = vt_column_count < 1? 1 : 0;
    {
        /* compute optimal work size */
        @ftyp@ work_size_query;
        fortran_int do_query = -1;
        fortran_int rv;
        LAPACK(@lapack_func@)(&jobz, &m, &n, 
                              (void*)a, &m, (void*)s, (void*)u, &m, 
                              (void*)vt, &vt_column_count,
                              &work_size_query, &do_query,
                              (void*)iwork, &rv);
        if (0!=rv)
            goto error;
        work_count = (fortran_int)work_size_query;
        work_size = (size_t)work_count * sizeof(@ftyp@);
    }

    mem_buff2 = malloc(work_size);
    if (!mem_buff2)
        goto error;

    work = mem_buff2;

    params->M = m;
    params->N = n;
    params->A = a;
    params->S = s;
    params->U = u;
    params->VT = vt;
    params->WORK = work;
    params->RWORK = NULL;
    params->IWORK = iwork;
    params->M = m;
    params->N = n;
    params->LDA = m;
    params->LDU = m;
    params->LDVT = vt_column_count;
    params->LWORK = work_count;
    params->JOBZ = jobz;

    return 1;
 error:
    free(mem_buff2);
    free(mem_buff2);
    memset(params, 0, sizeof(*params));

    return 0;
}

static inline fortran_int
call_@lapack_func@(GESDD_PARAMS_t *params)
{
    fortran_int rv;
    LAPACK(@lapack_func@)(&params->JOBZ, &params->M, &params->N,
                          params->A, &params->LDA, 
                          params->S,
                          params->U, &params->LDU,
                          params->VT, &params->LDVT,
                          params->WORK, &params->LWORK,
                          params->IWORK,
                          &rv);
    return rv;
}

/**end repeat**/

/**begin repeat
   #TYPE=CFLOAT,CDOUBLE#
   #ftyp=fortran_complex,fortran_doublecomplex#
   #frealtyp=fortran_real,fortran_doublereal#
   #typ=COMPLEX_t,DOUBLECOMPLEX_t#
   #lapack_func=cgesdd,zgesdd#
 */

static inline int
init_@lapack_func@(GESDD_PARAMS_t *params, char jobz, fortran_int m, fortran_int n)
{
    uint8_t *mem_buff = NULL, *mem_buff2 = NULL;
    uint8_t *a,*s, *u, *vt, *work, *rwork, *iwork;
    size_t a_size, s_size, u_size, vt_size, work_size, rwork_size, iwork_size;
    fortran_int u_row_count, vt_column_count, work_count;
    fortran_int min_m_n = m<n?m:n;

    if (!compute_urows_vtcolumns(jobz, m, n, &u_row_count, &vt_column_count))
        goto error;
    
    a_size = ((size_t)m)*((size_t)n)*sizeof(@ftyp@);
    s_size = ((size_t)min_m_n)*sizeof(@frealtyp@);
    u_size = ((size_t)u_row_count)*m*sizeof(@ftyp@);
    vt_size = n*((size_t)vt_column_count)*sizeof(@ftyp@);
    rwork_size = 'N'==jobz? 
        7*((size_t)min_m_n) : 
        (5*(size_t)min_m_n*(size_t)min_m_n + 5*(size_t)min_m_n);
    rwork_size *= sizeof(@ftyp@);
    iwork_size = 8*((size_t)min_m_n)*sizeof(fortran_int);

    mem_buff = malloc(a_size + s_size + u_size + vt_size + rwork_size + iwork_size);
    if (!mem_buff)
        goto error;

    a = mem_buff;
    s = a + a_size;
    u = s + s_size;
    vt = u + u_size;
    rwork = vt + vt_size;
    iwork = rwork + rwork_size;                      

    /* fix vt_column_count so that it is a valid lapack parameter (0 is not) */
    vt_column_count = vt_column_count < 1? 1 : 0;
    {
        /* compute optimal work size */
        @ftyp@ work_size_query;
        fortran_int do_query = -1;
        fortran_int rv;
        LAPACK(@lapack_func@)(&jobz, &m, &n, 
                              (void*)a, &m, (void*)s, (void*)u, &m, 
                              (void*)vt, &vt_column_count,
                              &work_size_query, &do_query,
                              (void*)rwork,
                              (void*)iwork, &rv);
        if (0!=rv)
            goto error;
        work_count = (fortran_int)((@typ@*)&work_size_query)->array[0];
        work_size = (size_t)work_count * sizeof(@ftyp@);
    }

    mem_buff2 = malloc(work_size);
    if (!mem_buff2)
        goto error;

    work = mem_buff2;

    params->A = a;
    params->S = s;
    params->U = u;
    params->VT = vt;
    params->WORK = work;
    params->RWORK = rwork;
    params->IWORK = iwork;
    params->M = m;
    params->N = n;
    params->LDA = m;
    params->LDU = m;
    params->LDVT = vt_column_count;
    params->LWORK = work_count;
    params->JOBZ = jobz;

    return 1;
 error:
    free(mem_buff2);
    free(mem_buff);
    memset(params, 0, sizeof(*params));

    return 0;
}

static inline fortran_int
call_@lapack_func@(GESDD_PARAMS_t *params)
{
    fortran_int rv;
    LAPACK(@lapack_func@)(&params->JOBZ, &params->M, &params->N,
                          params->A, &params->LDA,
                          params->S,
                          params->U, &params->LDU,
                          params->VT, &params->LDVT,
                          params->WORK, &params->LWORK,
                          params->RWORK,
                          params->IWORK,
                          &rv);
    return rv;
}
/**end repeat**/

/**begin repeat
   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #REALTYPE=FLOAT,DOUBLE,FLOAT,DOUBLE#
   #lapack_func=sgesdd,dgesdd,cgesdd,zgesdd#
 */
static inline void
release_@lapack_func@(GESDD_PARAMS_t* params)
{
    /* A and WORK contain allocated blocks */
    free(params->A);
    free(params->WORK);
    memset(params, 0, sizeof(*params));
}


static inline void
@TYPE@_svd_wrapper(char JOBZ, char **args, npy_intp* dimensions, npy_intp* steps)
{
    ptrdiff_t outer_steps[3];
    size_t iter;
    size_t outer_dim = *dimensions++;
    size_t op_count = (JOBZ=='N')?2:4;
    GESDD_PARAMS_t params;

    for (iter=0; iter < op_count; ++iter) {
        outer_steps[iter] = (ptrdiff_t) steps[iter];
    }
    steps += op_count;

    if (init_@lapack_func@(&params, JOBZ, (fortran_int)dimensions[0], (fortran_int)dimensions[1])) {
        LINEARIZE_DATA_t a_in, u_out, s_out, v_out;

        init_linearize_data(&a_in, params.N, params.M, steps[1], steps[0]);
        if ('N' == params.JOBZ) {
            /* only the singular values are wanted */
            fortran_int min_m_n = params.M < params.N? params.M : params.N;
            init_linearize_data(&s_out, 1, min_m_n, 0, steps[2]);
        } else {
            fortran_int u_columns, v_rows;
            fortran_int min_m_n = params.M < params.N? params.M : params.N;
            if ('S' == params.JOBZ) {
                u_columns = min_m_n;
                v_rows = min_m_n;
            } else {
                u_columns = params.M;
                v_rows = params.N;
            }
            init_linearize_data(&u_out,
                                u_columns, params.M,
                                steps[3], steps[2]);
            init_linearize_data(&s_out,
                                1, min_m_n,
                                0, steps[4]);
            init_linearize_data(&v_out, 
                                params.N, v_rows,
                                steps[6], steps[5]);
        }

        for (iter = 0; iter < outer_dim; ++iter) {
            /* copy the matrix in */
            linearize_@TYPE@_matrix(params.A, args[0], &a_in);
            call_@lapack_func@(&params);

            if ('N' == params.JOBZ) {
                delinearize_@REALTYPE@_matrix(args[1], params.S, &s_out);
            } else {
                delinearize_@TYPE@_matrix(args[1], params.U, &u_out);
                delinearize_@REALTYPE@_matrix(args[2], params.S, &s_out);
                delinearize_@TYPE@_matrix(args[3], params.VT, &v_out);
            }
            update_pointers((uint8_t**)args, outer_steps, op_count);
        }

        release_@lapack_func@(&params);
    }
}
/**end repeat*/

/* svd gufunc entry points */
/**begin repeat
   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
 */
static void
@TYPE@_svd_N(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    @TYPE@_svd_wrapper('N', args, dimensions, steps);
}

static void
@TYPE@_svd_S(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    @TYPE@_svd_wrapper('S', args, dimensions, steps);
}

static void
@TYPE@_svd_A(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    @TYPE@_svd_wrapper('A', args, dimensions, steps);
}

/**end repeat**/

/* -------------------------------------------------------------------------- */
                      /* ufunc registration  */

static void *array_of_nulls[] = {
    (void *)NULL,
    (void *)NULL,
    (void *)NULL,
    (void *)NULL,

    (void *)NULL,
    (void *)NULL,
    (void *)NULL,
    (void *)NULL,

    (void *)NULL,
    (void *)NULL,
    (void *)NULL,
    (void *)NULL,

    (void *)NULL,
    (void *)NULL,
    (void *)NULL,
    (void *)NULL
};

#define ARRAY_NAME(NAME) NAME ## _funcs
#define FUNCS_REAL(NAME) FLOAT_ ## NAME, DOUBLE_ ## NAME
#define FUNCS_REAL_COMPLEX(NAME) FUNCS_REAL(NAME), CFLOAT_ ## NAME, CDOUBLE_ ## NAME
#define GUFUNC_FUNC_ARRAY_REAL(NAME) static PyUFuncGenericFunction \
    ARRAY_NAME(NAME)[] = { FUNCS_REAL(NAME) }
#define GUFUNC_FUNC_ARRAY_REAL_COMPLEX(NAME) static PyUFuncGenericFunction \
    ARRAY_NAME(NAME)[] = { FUNCS_REAL_COMPLEX(NAME) }


GUFUNC_FUNC_ARRAY_REAL(inner1d);
GUFUNC_FUNC_ARRAY_REAL(innerwt);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(matrix_multiply);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(slogdet);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(det);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eighlo);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eighup);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eigvalshlo);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eigvalshup);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(solve);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(solve1);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(inv);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(cholesky);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(svd_N);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(svd_S);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(svd_A);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eig);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eigvals);

static char equal_2_types[] = {
    NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_CFLOAT,
    NPY_CDOUBLE, NPY_CDOUBLE
};

static char equal_3_types[] = {
    NPY_FLOAT, NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_CFLOAT, NPY_CFLOAT,
    NPY_CDOUBLE, NPY_CDOUBLE, NPY_CDOUBLE 
};

/* second result is logdet, that will always be a REAL */
static char slogdet_types[] = {
    NPY_FLOAT, NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_CFLOAT, NPY_FLOAT,
    NPY_CDOUBLE, NPY_CDOUBLE, NPY_DOUBLE 
};

static char eigh_types[] = {
    NPY_FLOAT, NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_FLOAT, NPY_CFLOAT,
    NPY_CDOUBLE, NPY_DOUBLE, NPY_CDOUBLE 
};

static char eighvals_types[] = {
    NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_FLOAT,
    NPY_CDOUBLE, NPY_DOUBLE
};

static char eig_types[] = {
    NPY_FLOAT, NPY_CFLOAT, NPY_CFLOAT,
    NPY_DOUBLE, NPY_CDOUBLE, NPY_CDOUBLE,
    NPY_CFLOAT, NPY_CFLOAT, NPY_CFLOAT,
    NPY_CDOUBLE, NPY_CDOUBLE, NPY_CDOUBLE
};

static char eigvals_types[] = {
    NPY_FLOAT, NPY_CFLOAT,
    NPY_DOUBLE, NPY_CDOUBLE,
    NPY_CFLOAT, NPY_CFLOAT,
    NPY_CDOUBLE, NPY_CDOUBLE
};

static char svd_1_1_types[] = {
    NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_FLOAT,
    NPY_CDOUBLE, NPY_DOUBLE
};

static char svd_1_3_types[] = {
    NPY_FLOAT,   NPY_FLOAT,   NPY_FLOAT,  NPY_FLOAT,
    NPY_DOUBLE,  NPY_DOUBLE,  NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT,  NPY_CFLOAT,  NPY_FLOAT,  NPY_CFLOAT,
    NPY_CDOUBLE, NPY_CDOUBLE, NPY_DOUBLE, NPY_CDOUBLE
};

typedef struct gufunc_descriptor_struct {
    char *name;
    char *signature;
    char *doc;
    int ntypes;
    int nin;
    int nout;
    PyUFuncGenericFunction *funcs;
    char *types;
} GUFUNC_DESCRIPTOR_t;

GUFUNC_DESCRIPTOR_t gufunc_descriptors [] = {
    {
        "inner1d",
        "(i),(i)->()",
        "inner on the last dimension and broadcast on the rest \n"\
        "    \"(i),(i)->()\" \n",
        2, 2, 1,
        inner1d_funcs,
        equal_2_types
    },

    {
        "innerwt",
        "(i),(i),(i)->()",
        "inner on the last dimension using 3 operands and broadcast on the rest \n"\
        "    \"(i),(i),(i)->()\" \n",
        2, 3, 1,
        innerwt_funcs,
        equal_3_types
    },

    {
        "matrix_multiply",
        "(m,p),(p,n)->(m,n)",
        "dot on the last two dimensions and broadcast on the rest \n"\
        "    \"(m,p),(p,n)->(m,n)\" \n",
        4, 2, 1,
        matrix_multiply_funcs,
        equal_3_types
    },

    {
        "slogdet",
        "(m,n)->(),()", /* should be (m,m)->(),() ... but the gufunc harness needs fixing */
        "slogdet on the last two dimensions and broadcast on the rest. \n"\
        "Results in two arrays, one with sign and the other with log of the determinants. \n"\
        "    \"(m,n)->(),()\" \n",
        4, 1, 2,
        slogdet_funcs,
        slogdet_types
    },

    {
        "det",
        "(m,n)->()", /* should be (m,m)->(),() ... but the gufunc harness needs fixing */
        "det of the last two dimensions and broadcast on the rest. \n"\
        "    \"(m,n)->()\" \n",
        4, 1, 1,
        det_funcs,
        equal_2_types
    },
    {
        "eigh_lo",
        "(m,n)->(m),(m,n)", /* should be (m,m)->(m),(m,m) ... but the gufunc harness needs fixing */
        "eigh on the last two dimension and broadcast to the rest, usine lower triangle \n"\
        "Results in a vector of eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m),(m,m)\" \n",
        4, 1, 2,
        eighlo_funcs,
        eigh_types
    },
    {
        "eigh_up",
        "(m,n)->(m),(m,n)", /* should be (m,m)->(m),(m,m) ... but the gufunc harness needs fixing */
        "eigh on the last two dimension and broadcast to the rest, using upper triangle. \n"\
        "Results in a vector of eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m),(m,m)\" \n",
        4, 1, 2,
        eighup_funcs,
        eigh_types
    },
    {
        "eigvalsh_lo",
        "(m,n)->(m)", /* should be (m,m)->(m), ... but the gufunc harness needs fixing */
        "eigh on the last two dimension and broadcast to the rest, using lower triangle. \n"\
        "Results in a vector of eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m)\" \n",
        4, 1, 1,
        eigvalshlo_funcs,
        eighvals_types
    },
    {
        "eigvalsh_up",
        "(m,n)->(m)", /* should be (m,m)->(m) ... but the gufunc harness needs fixing */
        "eigvalsh on the last two dimension and broadcast to the rest, using upper triangle. \n"\
        "Results in a vector of eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m)\" \n",
        4, 1, 1,
        eigvalshup_funcs,
        eighvals_types
    },
    {
        "solve",
        "(m,n),(m,p)->(m,p)",
        "solve the system a x = b, on the last two dimensions, broadcast to the rest. \n"\
        "Results in a matrices with the solutions. \n"\
        "    \"(m,m),(m,n)->(m,n)\" \n",
        4, 2, 1,
        solve_funcs,
        equal_3_types
    },
    {
        "solve1",
        "(m,n),(m)->(m)",
        "solve the system a x = b, for b being a vector, broadcast in the outer dimensions. \n"\
        "Results in vectors with the solutions. \n"\
        "    \"(m,m),(m)->(m)\" \n",
        4,2,1,
        solve1_funcs,
        equal_3_types
    },
    {
        "inv",
        "(m,n)->(m,n)",
        "compute the inverse of the last two dimensions and broadcast to the rest. \n"\
        "Results in the inverse matrices. \n"\
        "    \"(m,m)->(m,m)\" \n",
        4,1,1,
        inv_funcs,
        equal_2_types
    },
    {
        "cholesky",
        "(m,n)->(m,n)",
        "cholesky decomposition of hermitian positive-definite matrices. \n"\
        "Broadcast to all outer dimensions. \n"\
        "    \"(m,m)->(m,m)\" \n",
        4, 1, 1,
        cholesky_funcs,
        equal_2_types
    },
    {
        "svd_m",
        "(m,n)->(m)",
        "svd when n>=m. ",
        4, 1, 1,
        svd_N_funcs,
        equal_2_types
    },
    {
        "svd_n",
        "(m,n)->(n)",
        "svd when n<=m",
        4, 1, 1,
        svd_N_funcs,
        svd_1_1_types
    },
    {
        "svd_m_s",
        "(m,n)->(m,m),(m),(m,n)",
        "svd when m>=n",
        4, 1, 3,
        svd_S_funcs,
        svd_1_3_types
    },
    {
        "svd_n_s",
        "(m,n)->(m,n),(n),(n,n)",
        "svd when m>=n",
        4, 1, 3,
        svd_S_funcs,
        svd_1_3_types
    },
    {
        "svd_m_f",
        "(m,n)->(m,m),(m),(n,n)",
        "svd when m>=n",
        4, 1, 3,
        svd_A_funcs,
        svd_1_3_types
    },
    {
        "svd_n_f",
        "(m,n)->(m,m),(n),(n,n)",
        "svd when m>=n",
        4, 1, 3,
        svd_A_funcs,
        svd_1_3_types
    },
    {
        "eig",
        "(m,n)->(m),(m,n)",
        "eig on the last two dimension and broadcast to the rest. \n"\
        "Results in a vector with the  eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m),(m,m)\" \n",
        4, 1, 2,
        eig_funcs,
        eig_types
    },
    {
        "eigvals",
        "(m,n)->(m)",
        "eigvals on the last two dimension and broadcast to the rest. \n"\
        "Results in a vector of eigenvalues. \n"\
        "    \"(m,m)->(m),(m,m)\" \n",
        4, 1, 1,
        eigvals_funcs,
        eigvals_types
    }
};

static void
addUfuncs(PyObject *dictionary) {
    PyObject *f;
    int i;
    const int gufunc_count = sizeof(gufunc_descriptors)/sizeof(gufunc_descriptors[0]);
    for (i=0; i < gufunc_count; i++) {
        GUFUNC_DESCRIPTOR_t* d = &gufunc_descriptors[i];
        f = PyUFunc_FromFuncAndDataAndSignature(d->funcs, 
                                                array_of_nulls,
                                                d->types,
                                                d->ntypes,
                                                d->nin,
                                                d->nout,
                                                PyUFunc_None,
                                                d->name,
                                                d->doc,
                                                0,
                                                d->signature);
        PyDict_SetItemString(dictionary, d->name, f);
#if 0
        dump_ufunc_object((PyUFuncObject*) f);
#endif
        Py_DECREF(f);                                               
    }
}



/* -------------------------------------------------------------------------- */
                  /* Module initialization stuff  */

static PyMethodDef UMath_LinAlgMethods[] = {
    {NULL, NULL, 0, NULL}        /* Sentinel */
};

#if defined(NPY_PY3K)
static struct PyModuleDef moduledef = {
        PyModuleDef_HEAD_INIT,
        umath_linalg_module_name,
        NULL,
        -1,
        UMath_TestsMethods,
        NULL,
        NULL,
        NULL,
        NULL
};
#endif

#if defined(NPY_PY3K)
#define RETVAL m
PyObject *PyInit_umath_linalg(void)
#else
#define RETVAL
PyMODINIT_FUNC
initumath_linalg(void)
#endif
{
    PyObject *m;
    PyObject *d;
    PyObject *version;

#if defined(NPY_PY3K)
    m = PyModule_Create(&moduledef);
#else
    m = Py_InitModule(umath_linalg_module_name, UMath_LinAlgMethods);
#endif
    if (m == NULL)
        return RETVAL;

    import_array();
    import_ufunc();

    d = PyModule_GetDict(m);

    version = PyString_FromString(umath_linalg_version_string);
    PyDict_SetItemString(d, "__version__", version);
    Py_DECREF(version);

    /* Load the ufunc operators into the module's namespace */
    addUfuncs(d);
    
    if (PyErr_Occurred()) {
        PyErr_SetString(PyExc_RuntimeError,
                        "cannot load umath_linalg module.");
    }

    return RETVAL;
}
