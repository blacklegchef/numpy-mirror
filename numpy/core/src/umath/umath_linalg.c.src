/* -*- c -*- */

/*
 *****************************************************************************
 **                            INCLUDES                                     **
 *****************************************************************************
 */
#define NPY_NO_DEPRECATED_API NPY_API_VERSION

#include "Python.h"
#include "numpy/arrayobject.h"
#include "numpy/ufuncobject.h"

#include "npy_pycompat.h"

#include "npy_config.h"

#ifndef CBLAS_HEADER
#define CBLAS_HEADER "cblas.h"
#endif

#ifndef CLAPACK_HEADER
#define CLAPACK_HEADER "clapack.h"
#endif

#include CBLAS_HEADER
#include CLAPACK_HEADER

#include <stddef.h>
#include <stdio.h>
#include <assert.h>


#define TRACE do { printf ("%s:%d:%s\n", __FILE__, __LINE__, __FUNCTION__); } while (0)

/*
 *****************************************************************************
 *                    BLAS/LAPACK calling macros                             *
 *****************************************************************************
 */
#define CBLAS(FUNC) cblas_ ## FUNC
#define LAPACK_T(FUNC) printf("Calling LAPACK ( " # FUNC " )\n"); FUNC ## _
#define LAPACK(FUNC) FUNC ## _

/* TODO: Fix this properly */
typedef __CLPK_integer fortran_int;
typedef __CLPK_real    fortran_real;
typedef __CLPK_doublereal fortran_doublereal;
typedef __CLPK_complex fortran_complex;
typedef __CLPK_doublecomplex fortran_doublecomplex;

#if 1
#  define INTERNAL
#else
#  define INTERNAL static
#endif

/*
 *****************************************************************************
 **                      Some handy constants                               **
 *****************************************************************************
 */

static const char* umath_linalg_module_name =  "umath_linalg";

static const float  s_one          =  1.0f;
static const float  s_zero         =  0.0f;
static const float  s_minus_one    = -1.0f;
static const float  s_ninf         = -1.0f/0.0f; 
static const double d_one          =  1.0;
static const double d_zero         =  0.0;
static const double d_minus_one    = -1.0;
static const double d_ninf         = -1.0/0.0;
static const float  c_one[2]       = {  1.0f, 0.0f };
static const float  c_zero[2]      = {  0.0f, 0.0f };
static const float  c_minus_one[2] = { -1.0f, 0.0f };
static const float  c_ninf[2]      = { -1.0f/0.0f, 0.0f };
static const double z_one[2]       = {  1.0,  0.0 };
static const double z_zero[2]      = {  0.0,  0.0 };
static const double z_minus_one[2] = { -1.0,  0.0 };
static const double z_ninf[2]      = { -1.0/0.0, 0.0 };


/*
 *****************************************************************************
 **               Structs used for data rearrangement                       **
 *****************************************************************************
 */


/* this struct contains information about how to linearize in a local buffer
   a matrix so that it can be used by blas functions.
   All strides are specified in number of elements (similar to what blas expects)

   dst_row_strides: number of elements between different row. Matrix is considered
                    row-major
   dst_column_strides: number of elements between differnt columns in the
                    destination buffer
   rows: number of rows of the matrix
   columns: number of columns of the matrix
   src_row_strides: strides needed to access the next row in the source matrix
   src_column_strides: strides needed to access the next column in the source
                       matrix
 */
typedef struct linearize_data_struct
{
  size_t     rows;
  size_t     columns;
  ptrdiff_t  row_strides;
  ptrdiff_t  column_strides;
} LINEARIZE_DATA_t;

static inline void
init_linearize_data(LINEARIZE_DATA_t *lin_data, 
                    int rows, 
                    int columns, 
                    ptrdiff_t row_strides, 
                    ptrdiff_t column_strides)
{
    lin_data->rows = rows;
    lin_data->columns = columns;
    lin_data->row_strides = row_strides;
    lin_data->column_strides = column_strides;
}

static inline void
dump_ufunc_object(PyUFuncObject* ufunc)
{
    printf("\n\n%s '%s' (%d input(s), %d output(s), %d specialization(s).\n",
           ufunc->core_enabled? "generalized ufunc" : "scalar ufunc",
           ufunc->name, ufunc->nin, ufunc->nout, ufunc->ntypes);
    if (ufunc->core_enabled) {
        int arg;
        int dim;
        printf("\t%s (%d dimension(s) detected).\n",
               ufunc->core_signature, ufunc->core_num_dim_ix);

        for (arg = 0; arg < ufunc->nargs; arg++){
            int * arg_dim_ix = ufunc->core_dim_ixs + ufunc->core_offsets[arg];
            printf("\t\targ %d (%s) has %d dimension(s): (",
                   arg, arg < ufunc->nin? "INPUT" : "OUTPUT", ufunc->core_num_dims[arg]);
            for (dim = 0; dim < ufunc->core_num_dims[arg]; dim ++) {
                printf(" %d", arg_dim_ix[dim]);
            }
            printf(" )\n");
        }
    }
}

static inline void
dump_linearize_data(const char* name, const LINEARIZE_DATA_t* params)
{
    printf("\n\t%s rows: %zd columns: %zd"
           "\n\t\trow_strides: %td column_strides: %td"
           "\n", name, params->rows, params->columns,
           params->row_strides, params->column_strides);
}

static inline void
print_npy_float(npy_float s)
{
    printf(" %8.4f", s);
}
static inline void
print_npy_double(npy_double d)
{
    printf(" %10.6f", d);
}
static inline void
print_npy_cfloat(npy_cfloat c)
{
    float* c_parts = (float*)&c;
    printf(" %8.4f + %8.4fj", c_parts[0], c_parts[1]);
}
static inline void
print_npy_cdouble(npy_cdouble z)
{
    double* z_parts = (double*)&z;
    printf(" %8.4f + %8.4fj", z_parts[0], z_parts[1]);
}

/**begin repeat
   #type=npy_float,npy_double,npy_cfloat,npy_cdouble#
   #format=%8.4f,%10.6f,%8.4f,%10.6f#
 */
static inline void
dump_@type@_matrix(const char* name, size_t rows, size_t columns, const @type@* ptr)
{
    size_t i,j;

    printf("\n%s (%zd, %zd)\n", name, rows, columns);
    for (i=0; i<rows; i++)
    {
        printf("(");
        for (j=0; j<columns; j++)
        {
            print_@type@(*ptr++);
        }
        printf(" )\n");
    }
}
/**end repeat**/


/*
 *****************************************************************************
 **                            Basics                                       **
 *****************************************************************************
 */

#define INIT_OUTER_LOOP_1       \
    npy_intp dN = *dimensions++;\
    npy_intp N_;                \
    npy_intp s0 = *steps++;

#define INIT_OUTER_LOOP_2       \
    INIT_OUTER_LOOP_1           \
    npy_intp s1 = *steps++;

#define INIT_OUTER_LOOP_3       \
    INIT_OUTER_LOOP_2           \
    npy_intp s2 = *steps++;

#define INIT_OUTER_LOOP_4       \
    INIT_OUTER_LOOP_3           \
    npy_intp s3 = *steps++;

#define BEGIN_OUTER_LOOP_2      \
    for (N_ = 0; N_ < dN; N_++, args[0] += s0, args[1] += s1) {

#define BEGIN_OUTER_LOOP_3      \
    for (N_ = 0; N_ < dN; N_++, args[0] += s0, args[1] += s1, args[2] += s2) {

#define BEGIN_OUTER_LOOP_4      \
    for (N_ = 0; N_ < dN; N_++, args[0] += s0, args[1] += s1, args[2] += s2, args[3] += s3) {

#define END_OUTER_LOOP  }

static void inline
update_pointers(uint8_t** bases, ptrdiff_t* offsets, size_t count)
{
    size_t i;
    for (i=0; i < count; ++i) {
        bases[i] += offsets[i];
    }
}

/*
 *****************************************************************************
 **                             HELPER FUNCS                                **
 *****************************************************************************
 */

/* rearranging of 2D matrices using blas */

/**begin repeat

    #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
    #typ=npy_float,npy_double,npy_cfloat,npy_cdouble# 
    #cblas_type=s,d,c,z#
 */
static inline void *
linearize_@TYPE@_matrix(void *dst_in, void *src_in,const LINEARIZE_DATA_t* data)
{
    @typ@ *src = (@typ@ *) src_in;
    @typ@ *dst = (@typ@ *) dst_in;

    if (dst) {
        int i;
        @typ@* rv = dst;
        for (i=0; i< data->rows; i++) {
            CBLAS(@cblas_type@copy)((fortran_int)data->columns,
                                    src, (fortran_int)(data->column_strides/sizeof(@typ@)),
                                    dst, (fortran_int)1);
            src += data->row_strides/sizeof(@typ@);
            dst += data->columns;
        } 
        return rv;
    } else {
        return src;
    }
}

static inline void *
delinearize_@TYPE@_matrix(void *dst_in, void *src_in,const LINEARIZE_DATA_t* data)
{
    @typ@ *src = (@typ@ *) src_in;
    @typ@ *dst = (@typ@ *) dst_in;

    if (src) {
        int i;
        @typ@ *rv = src;
        for (i=0; i < data->rows; i++) {
            CBLAS(@cblas_type@copy)((fortran_int)data->columns,
                                    src, (fortran_int)1,
                                    dst, (fortran_int)(data->column_strides/sizeof(@typ@)));
            src += data->columns;
            dst += data->row_strides/sizeof(@typ@);
        }

        return rv;
    } else {
        return src;
    }
}

/**end repeat**/


/*
 *****************************************************************************
 **                             UFUNC LOOPS                                 **
 *****************************************************************************
 */

/**begin repeat

   #TYPE=FLOAT,DOUBLE#
   #typ=npy_float, npy_double#
   #cblas_dot=cblas_sdot, cblas_ddot# 

*/

static inline void 
@TYPE@_inner1d_blas(char **args, npy_intp* dimensions, npy_intp * steps)
{
    INIT_OUTER_LOOP_3
    const size_t sot = sizeof(@typ@);

    int dim = (int) dimensions[0];
    int is1 = (int)(steps[0]/sot), is2 = (int)(steps[1]/sot);

    BEGIN_OUTER_LOOP_3
        @typ@ * ip1 = (@typ@*)args[0], *ip2 = (@typ@*)args[1];
        *(@typ@*)(args[2]) = @cblas_dot@(dim, ip1, is1, ip2, is2);
    END_OUTER_LOOP
}

static inline void 
@TYPE@_inner1d_std(char **args, npy_intp* dimensions, npy_intp * steps)
{
    INIT_OUTER_LOOP_3
    npy_intp di = dimensions[0];
    npy_intp i;
    npy_intp is1=steps[0], is2=steps[1];
    BEGIN_OUTER_LOOP_3
        char *ip1=args[0], *ip2=args[1], *op=args[2];
    @typ@ sum = 0;
        for (i = 0; i < di; i++) {
            sum += (*(@typ@ *)ip1) * (*(@typ@ *)ip2);
            ip1 += is1;
            ip2 += is2;
        }
        *(@typ@ *)op = sum;
    END_OUTER_LOOP
}

INTERNAL void
@TYPE@_inner1d(char **args, npy_intp *dimensions, npy_intp *steps,
               void *NPY_UNUSED(func))
{
    const size_t sot = sizeof(@typ@);
    /* 
     * use blas if the stride is a multiple of datatype size in the inputs
     * it should be the common case 
     */

    if ((0 == (steps[3] % sot)) &&
        (0 == (steps[4] % sot))) {
        /* use blas */
        @TYPE@_inner1d_blas(args, dimensions, steps);
    } else {
        /* use standard version */
        @TYPE@_inner1d_std(args, dimensions, steps);
    }
}

/**end repeat**/


/* -------------------------------------------------------------------------- */

/**begin repeat

   #TYPE=FLOAT,DOUBLE#
   #typ=npy_float, npy_double# 

*/

/*
 *  This implements the function
 *        out[n] = sum_i { in1[n, i] * in2[n, i] * in3[n, i] }.
 */

INTERNAL void
@TYPE@_innerwt(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    INIT_OUTER_LOOP_4
    npy_intp di = dimensions[0];
    npy_intp i;
    npy_intp is1=steps[0], is2=steps[1], is3=steps[2];
    BEGIN_OUTER_LOOP_4
        char *ip1=args[0], *ip2=args[1], *ip3=args[2], *op=args[3];
        @typ@ sum = 0;
        for (i = 0; i < di; i++) {
            sum += (*(@typ@ *)ip1) * (*(@typ@ *)ip2) * (*(@typ@ *)ip3);
            ip1 += is1;
            ip2 += is2;
            ip3 += is3;
        }
        *(@typ@ *)op = sum;
    END_OUTER_LOOP
}

/**end repeat**/


/* -------------------------------------------------------------------------- */
                        /* Matrix Multiply */

typedef struct gemm_params_struct
{
    fortran_int m,n,k; // note there is a relationship between this and lin_data rows
                 // & columns but the actual relationship is dependent on trans.
    fortran_int strides[3]; // strides to use in gemm call
    void *buff[3];  // memory buff for the operand to use in blas call
    LINEARIZE_DATA_t lin_data[3];
    void *allocated_data;
    int   trans[2]; // use transpose
} GEMM_PARAMS_t;

static inline void
dump_gemm_params(const GEMM_PARAMS_t* params)
{
    printf("\n\ngemm_params: src1: %s transposed src2: %s transposed"
           "\n\tM: %d N: %d K: %d",
           params->trans[0] == CblasNoTrans? "NOT" : "",
           params->trans[1] == CblasNoTrans? "NOT" : "",
           (int)params->m, (int)params->n, (int)params->k);
    dump_linearize_data("src1", &params->lin_data[0]);
    dump_linearize_data("src2", &params->lin_data[1]);
    dump_linearize_data("dst", &params->lin_data[2]);
}

static inline void
init_gemm_params(GEMM_PARAMS_t *params,
                 char** args,
                 npy_intp *dimensions,
                 npy_intp* steps,
                 size_t size_of_type)
{
    int i, m, n, k;

    m = (int) dimensions[0];
    k = (int) dimensions[1];
    n = (int) dimensions[2];

    for (i = 0; i < sizeof(params->trans)/sizeof(params->trans[0]); i++)
        params->trans[i] = CblasNoTrans;

    params->m = m;
    params->n = n;
    params->k = k;

    // this should be initialized later when it is known whether we are doing it
    // in-place or in a tmp buffer.
    for (i = 0 ; i < sizeof(params->strides)/sizeof(params->strides[0]); i++)
       params->strides[i] = 0;

    init_linearize_data(&params->lin_data[0], m, k, steps[0], steps[1]);
    init_linearize_data(&params->lin_data[1], k, n, steps[2], steps[3]);
    init_linearize_data(&params->lin_data[2], m, n, steps[4], steps[5]);

    /* compute size and reserve if needed local buffers */
    {
        size_t buff_size[3];
        size_t total_buff_size, offset;

        for (i = 0; i < 3; i++) {
            if (params->lin_data[i].column_strides == size_of_type) {
                /* do it *in-place* */
                buff_size[i] = 0;
                params->strides[i] = (fortran_int)(steps[i*2] / size_of_type);
            } else {
                /* buffer needed to linearize */
                int rows = (int)params->lin_data[i].rows;
                int columns = (int)params->lin_data[i].columns;
                buff_size[i] = rows * columns * size_of_type;
                params->strides[i] = columns;
            }
        }
        
        total_buff_size = buff_size[0] + buff_size[1] + buff_size[2];
        if (total_buff_size) {
            params->allocated_data = (uint8_t*)malloc(total_buff_size);
        } else {
            params->allocated_data = NULL;
        }
        
        offset = 0;
        for (i=0; i<3; i++) {
            if (buff_size[i] == 0) {
                /* inplace */ 
                params->buff[i] = NULL;
            } else {
                /* an intermediate copy will be needed */
                params->buff[i] = (void*)(params->allocated_data + offset);
                offset += buff_size[i];
            }
        }

        assert(total_buff_size == offset);
    }
}

static inline void
release_gemm_params(GEMM_PARAMS_t * params)
{
    free(params->allocated_data);
    params->allocated_data = NULL;
}


/**begin repeat

   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #typ=npy_float,npy_double,npy_cfloat,npy_cdouble#
   #cblas_type=s,d,c,z#
*/


INTERNAL void
@TYPE@_matrix_multiply(char **args, 
                       npy_intp *dimensions, 
                       npy_intp *steps, 
                       void *NPY_UNUSED(func))
{
    /* 
     * everything is setup in a way that makes things work. BLAS gemm can be
     * be called without rearranging nor using weird stuff, as matrices are
     * in the expected way in memory.
     * This is just a loop calling blas.
     */
    GEMM_PARAMS_t params;
    INIT_OUTER_LOOP_3

    init_gemm_params(&params, args, dimensions, steps, sizeof(@typ@));

    BEGIN_OUTER_LOOP_3
        /* just call the appropriate multiply and update pointers */
        @typ@ *src1 = linearize_@TYPE@_matrix(params.buff[0],
                                              args[0],
                                              &params.lin_data[0]);
        @typ@ *src2 = linearize_@TYPE@_matrix(params.buff[1],
                                              args[1],
                                              &params.lin_data[1]);
        @typ@ *dst = params.buff[2] ? params.buff[2] : (@typ@ *) args[2];

        /* linearize source operands if needed */
        CBLAS(@cblas_type@gemm)(CblasRowMajor,
                                params.trans[0], params.trans[1],
                                params.m, params.n, params.k, 
                                @cblas_type@_one, // alpha
                                src1, params.strides[0],
                                src2, params.strides[1],
                                @cblas_type@_zero, // beta
                                dst, params.strides[2]);
        
        delinearize_@TYPE@_matrix(args[2],
                                  params.buff[2],
                                  &params.lin_data[2]);
    END_OUTER_LOOP

    release_gemm_params(&params);
}
/**end repeat**/


/* -------------------------------------------------------------------------- */
                          /* Determinants */

/**begin repeat

   #TYPE=FLOAT,DOUBLE#
   #typ=npy_float, npy_double#
   #log_func=npy_logf,npy_log#
   #exp_func=npy_expf,npy_exp#
   #zero=0.0f,0.0#
*/
static inline @typ@
@TYPE@_mult(@typ@ op1, @typ@ op2)
{
    return op1 * op2;
}

static inline void
@TYPE@_slogdet_from_factored_diagonal(@typ@* src,
                                      fortran_int m,
                                      @typ@ *sign,
                                      @typ@ *logdet)
{
    @typ@ acc_sign = *sign;
    @typ@ acc_logdet = @zero@;
    int i;
    for (i = 0; i < m; i++) {
        @typ@ abs_element = *src;
        if (abs_element < @zero@) {
            acc_sign = -acc_sign;
            abs_element = -abs_element;
        }

        acc_logdet += @log_func@(abs_element);
        src += m+1;
    }

    *sign = acc_sign;
    *logdet = acc_logdet;
}

static inline @typ@
@TYPE@_det_from_slogdet(@typ@ sign, @typ@ logdet)
{
    @typ@ result = sign * @exp_func@(logdet);
    return result;
}

/**end repeat**/

/**begin repeat

   #TYPE=CFLOAT,CDOUBLE#
   #typ=npy_cfloat, npy_cdouble#
   #basetyp=npy_float, npy_double#
   #abs_func=npy_cabsf, npy_cabs#
   #log_func=npy_logf, npy_log#
   #exp_func=npy_expf, npy_exp#
   #zero=0.0f,0.0#
*/
#define RE(COMPLEX) (((@basetyp@*)(&COMPLEX))[0])
#define IM(COMPLEX) (((@basetyp@*)(&COMPLEX))[1])

static inline @typ@
@TYPE@_mult(@typ@ op1, @typ@ op2)
{
    @typ@ rv;

    RE(rv) = RE(op1)*RE(op2) - IM(op1)*IM(op2);
    IM(rv) = RE(op1)*IM(op2) - IM(op1)*RE(op2);

    return rv;
}


static inline void
@TYPE@_slogdet_from_factored_diagonal(@typ@* src,
                                      fortran_int m,
                                      @typ@ *sign, 
                                      @basetyp@ *logdet)
{
    int i;
    @typ@ sign_acc = *sign;
    @basetyp@ logdet_acc = @zero@;

    for (i = 0; i < m; i++)
    {
        @basetyp@ abs_element = @abs_func@(*src);
        @typ@ sign_element;
        RE(sign_element) = RE(*src) / abs_element;
        IM(sign_element) = IM(*src) / abs_element;

        sign_acc = @TYPE@_mult(sign_acc, sign_element);
        logdet_acc += @log_func@(abs_element);
        src += m + 1;
    }

    *sign = sign_acc;
    *logdet = logdet_acc;
}

static inline @typ@
@TYPE@_det_from_slogdet(@typ@ sign, @basetyp@ logdet)
{
    @typ@ tmp;
    RE(tmp) = @exp_func@(logdet);
    IM(tmp) = @zero@;
    return @TYPE@_mult(sign, tmp);
}
#undef RE
#undef IM

/**end repeat**/

/* As in the linalg package, the determinant is computed via LU factorization
 * using LAPACK.
 * slogdet computes sign + log(determinant).
 * det computes sign * exp(slogdet).
 */ 
/**begin repeat

   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #typ=npy_float,npy_double,npy_cfloat,npy_cdouble#
   #basetyp=npy_float,npy_double,npy_float,npy_double#
   #cblas_type=s,d,c,z#
*/

static inline void
@TYPE@_slogdet_single_element(fortran_int m, 
                              void* src, 
                              fortran_int* pivots, 
                              @typ@ *sign, 
                              @basetyp@ *logdet)
{
    fortran_int info = 0;
    int i;
    /* note: done in place */
    LAPACK(@cblas_type@getrf)(&m, &m, (void *)src, &m, pivots, &info);
    
    if (info == 0)
    {
        int change_sign = 0;
        /* note: fortran uses 1 based indexing */
        for (i=0; i < m; i++)
        {
            change_sign += (pivots[i] != (i+1));
        }
    
        memcpy(sign, (change_sign % 2)? &@cblas_type@_minus_one : &@cblas_type@_one, sizeof(*sign));
        @TYPE@_slogdet_from_factored_diagonal(src, m, sign, logdet);
    } else {
        memcpy(sign, &@cblas_type@_zero, sizeof(*sign));
        memcpy(logdet, &@cblas_type@_ninf, sizeof(*logdet));
    }
    
}

INTERNAL void
@TYPE@_slogdet(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    fortran_int m;
    uint8_t* tmp_buff = NULL;
    size_t matrix_size;
    size_t pivot_size;
    /* notes:
     *   matrix will need to be copied always, as factorization in lapack is made inplace
     *   matrix will need to be in column-major order, as expected by lapack code (fortran)
     *   always a square matrix
     *   need to allocate memory for both, matrix_buffer and pivot buffer
     */
    INIT_OUTER_LOOP_3
    m = (fortran_int) dimensions[0];
    matrix_size = m*m*sizeof(@typ@);
    pivot_size = m*sizeof(fortran_int); 
    tmp_buff = (uint8_t *)malloc(matrix_size + pivot_size); 

    if (tmp_buff)
    {
        LINEARIZE_DATA_t lin_data;
        /* swapped steps to get matrix in FORTRAN order */
        init_linearize_data(&lin_data, m, m, (ptrdiff_t)steps[1], (ptrdiff_t)steps[0]);
        BEGIN_OUTER_LOOP_3
            linearize_@TYPE@_matrix(tmp_buff, args[0], &lin_data);
            @TYPE@_slogdet_single_element(m,
                                          (void*)tmp_buff,
                                          (fortran_int*)(tmp_buff+matrix_size),
                                          (@typ@*)args[1],
                                          (@basetyp@*)args[2]); 
        END_OUTER_LOOP

        free(tmp_buff);
    }
}

INTERNAL void
@TYPE@_det(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    fortran_int m;
    uint8_t* tmp_buff;
    size_t matrix_size;
    size_t pivot_size;
    /* notes:
     *   matrix will need to be copied always, as factorization in lapack is made inplace
     *   matrix will need to be in column-major order, as expected by lapack code (fortran)
     *   always a square matrix
     *   need to allocate memory for both, matrix_buffer and pivot buffer
     */
    INIT_OUTER_LOOP_2
    m = (fortran_int) dimensions[0];
    matrix_size = m*m*sizeof(@typ@);
    pivot_size = m*sizeof(fortran_int); 
    tmp_buff = (uint8_t *)malloc(matrix_size + pivot_size); 

    if (tmp_buff)
    {
        LINEARIZE_DATA_t lin_data;
        @typ@ sign;
        @basetyp@ logdet;
        /* swapped steps to get matrix in FORTRAN order */
        init_linearize_data(&lin_data, m, m, (ptrdiff_t)steps[1], (ptrdiff_t)steps[0]);

        BEGIN_OUTER_LOOP_2
            linearize_@TYPE@_matrix(tmp_buff, args[0], &lin_data);
            @TYPE@_slogdet_single_element(m,
                                          (void*)tmp_buff,
                                          (fortran_int*)(tmp_buff+matrix_size),
                                          &sign,
                                          &logdet);
            *(@typ@ *)args[1] = @TYPE@_det_from_slogdet(sign, logdet);
        END_OUTER_LOOP

        free(tmp_buff);
    }
}
/**end repeat**/

/* -------------------------------------------------------------------------- */
                          /* Eigh family */

typedef struct eigh_params_struct {
    void *A;     /* matrix */
    void *W;     /* eigenvalue vector */
    void *WORK;  /* main work buffer */
    void *RWORK; /* secondary work buffer (for complex versions) */
    void *IWORK; 
    fortran_int N;
    fortran_int LWORK;
    fortran_int LRWORK;
    fortran_int LIWORK;
    char JOBZ;
    char UPLO;
} EIGH_PARAMS_t;

/**begin repeat

   #TYPE=FLOAT,DOUBLE#
   #typ=npy_float,npy_double#
   #ftyp=fortran_real,fortran_doublereal#
   #lapack_func=ssyevd,dsyevd#
*/

/*
 * Initialize the parameters to use in for the lapack function _syevd
 * Handles buffer allocation
 */
static inline int
init_@lapack_func@(char JOBZ, char UPLO,
                   fortran_int N, EIGH_PARAMS_t *params)
{
    uint8_t *mem_buff = NULL;
    uint8_t *mem_buff2 = NULL;
    @typ@ query_work_size;
    fortran_int query_iwork_size;
    fortran_int lwork  = -1;
    fortran_int liwork = -1;
    fortran_int info;
    uint8_t *a, *w, *work, *iwork;
    size_t alloc_size = N*(N+1)*sizeof(@typ@);

    mem_buff = malloc(alloc_size);
  
    if (!mem_buff)
        goto error;
    a = mem_buff;
    w = mem_buff + N*N*sizeof(@typ@);
    LAPACK(@lapack_func@)(&JOBZ, &UPLO, &N, 
                          (@ftyp@*)a, &N, (@ftyp@*)w,
                          &query_work_size, &lwork,
                          &query_iwork_size, &liwork,
                          &info);

    if (info != 0)
        goto error;

    lwork = (fortran_int)query_work_size;
    liwork = query_iwork_size;
    mem_buff2 = malloc(lwork*sizeof(@typ@) + liwork*sizeof(fortran_int));
    if (!mem_buff2)
        goto error;

    work = mem_buff2;
    iwork = mem_buff2 + lwork*sizeof(@typ@);

    params->A = a;
    params->W = w;
    params->WORK = mem_buff2;
    params->RWORK = NULL; /* unused */
    params->IWORK = iwork;
    params->N = N;
    params->LWORK = lwork;
    params->LRWORK = 0; /* unused */
    params->LIWORK = liwork;
    params->JOBZ = JOBZ;
    params->UPLO = UPLO;
    
    return 1;

 error:
    /* something failed */
    memset(params, 0, sizeof(*params));
    free(mem_buff2);
    free(mem_buff);

    return 0;
}

static inline void
release_@lapack_func@(EIGH_PARAMS_t *params)
{
    /* allocated memory in A and WORK */
    free(params->A);
    free(params->WORK);
    memset(params, 0, sizeof(*params));
}

static inline fortran_int
lapack_@lapack_func@(EIGH_PARAMS_t *params)
{
    fortran_int rv;
    LAPACK(@lapack_func@)(&params->JOBZ, &params->UPLO, &params->N,
                          params->A, &params->N, params->W, 
                          params->WORK, &params->LWORK,
                          params->IWORK, &params->LIWORK,
                          &rv);
    return rv;
}
/**end repeat**/

/**begin repeat

   #TYPE=CFLOAT,CDOUBLE#
   #typ=npy_cfloat,npy_cdouble#
   #basetyp=npy_float,npy_double#
   #ftyp=fortran_complex,fortran_doublecomplex#
   #fbasetyp=fortran_real,fortran_doublereal#
   #lapack_func=cheevd,zheevd#
*/
/*
 * Initialize the parameters to use in for the lapack function _heev
 * Handles buffer allocation
 */
static inline int
init_@lapack_func@(char JOBZ, char UPLO,
                   fortran_int N, EIGH_PARAMS_t *params)
{
    uint8_t *mem_buff = NULL;
    uint8_t *mem_buff2 = NULL;
    @ftyp@ query_work_size;
    @fbasetyp@ query_rwork_size;
    fortran_int query_iwork_size;
    fortran_int lwork = -1;
    fortran_int lrwork = -1;
    fortran_int liwork = -1;
    uint8_t *a, *w, *work, *rwork, *iwork;
    fortran_int info;

    mem_buff = malloc(N*N*sizeof(@typ@)+N*sizeof(@basetyp@));
    if (!mem_buff) 
        goto error;
    a = mem_buff;
    w = mem_buff+N*N*sizeof(@typ@);
    
    LAPACK(@lapack_func@)(&JOBZ, &UPLO, &N, 
                          (@ftyp@*)a, &N, (@fbasetyp@*)w,
                          &query_work_size, &lwork,
                          &query_rwork_size, &lrwork,
                          &query_iwork_size, &liwork,
                          &info);
    if (info != 0)
        goto error;

    lwork = (fortran_int)*(@fbasetyp@*)&query_work_size;
    lrwork = (fortran_int)query_rwork_size;
    liwork = query_iwork_size;

    mem_buff2 = malloc(lwork*sizeof(@typ@) + lrwork*sizeof(@basetyp@) + liwork*sizeof(fortran_int));
    if (!mem_buff2)
        goto error;
    work = mem_buff2;
    rwork = work + lwork*sizeof(@typ@);
    iwork = rwork + lrwork*sizeof(@basetyp@);

    params->A = a;
    params->W = w;
    params->WORK = work;
    params->RWORK = rwork;
    params->IWORK = iwork;
    params->N = N;
    params->LWORK = lwork;
    params->LRWORK = lrwork;
    params->LIWORK = liwork;
    params->JOBZ = JOBZ;
    params->UPLO = UPLO;
    
    return 1;

    /* something failed */
error:
    memset(params, 0, sizeof(*params));
    free(mem_buff2);
    free(mem_buff);

    return 0;
}

static inline void
release_@lapack_func@(EIGH_PARAMS_t *params)
{
    /* allocated memory in A and WORK */
    free(params->A);
    free(params->WORK);
    memset(params, 0, sizeof(*params));
}

static inline fortran_int
lapack_@lapack_func@(EIGH_PARAMS_t *params)
{
    fortran_int rv;
    LAPACK(@lapack_func@)(&params->JOBZ, &params->UPLO, &params->N,
                          params->A, &params->N, params->W, 
                          params->WORK, &params->LWORK,
                          params->RWORK, &params->LRWORK,
                          params->IWORK, &params->LIWORK,
                          &rv);
    return rv;
}
/**end repeat**/

/**begin repeat
   
   #TYPE=FLOAT,DOUBLE,CFLOAT,CDOUBLE#
   #BASETYPE=FLOAT,DOUBLE,FLOAT,DOUBLE#
   #typ=npy_float,npy_double,npy_cfloat,npy_cdouble#
   #basetyp=npy_float,npy_double,npy_float,npy_double#
   #lapack_func=ssyevd,dsyevd,cheevd,zheevd#
  **/ 
/*
 * (M,M)->(M,)(M,M)
 * dimensions[1] -> M
 * args[0] -> A[in]
 * args[1] -> W
 * args[2] -> A[out]
 */
static inline void
@TYPE@_eigh_wrapper(char JOBZ, char UPLO, char**args, npy_intp* dimensions, npy_intp* steps)
{
    ptrdiff_t outer_steps[3];
    size_t iter;
    size_t outer_dim = *dimensions++;
    size_t op_count = (JOBZ=='N')?2:3;
    EIGH_PARAMS_t eigh_params;

    for (iter=0; iter < op_count; ++iter) {
        outer_steps[iter] = (ptrdiff_t) steps[iter];
    }
    steps += op_count;

    if (init_@lapack_func@(JOBZ, UPLO, (fortran_int)dimensions[0], &eigh_params)) {
        LINEARIZE_DATA_t matrix_in_ld;
        LINEARIZE_DATA_t eigenvectors_out_ld;
        LINEARIZE_DATA_t eigenvalues_out_ld;

        init_linearize_data(&matrix_in_ld,
                            eigh_params.N, eigh_params.N,
                            steps[1], steps[0]);
        init_linearize_data(&eigenvalues_out_ld,
                            1, eigh_params.N,
                            0, steps[2]);
        if ('V' == eigh_params.JOBZ) {
            init_linearize_data(&eigenvectors_out_ld, 
                                eigh_params.N, eigh_params.N,
                                steps[4], steps[3]);
        }

        for (iter = 0; iter < outer_dim; ++iter) {
            /* copy the matrix in */
            linearize_@TYPE@_matrix(eigh_params.A, args[0], &matrix_in_ld);
            lapack_@lapack_func@(&eigh_params);
            delinearize_@BASETYPE@_matrix(args[1], eigh_params.W, &eigenvalues_out_ld);
            
            if ('V' == eigh_params.JOBZ) {
                delinearize_@TYPE@_matrix(args[2], eigh_params.A, &eigenvectors_out_ld);
            }
            update_pointers((uint8_t**)args, outer_steps, op_count);
        }

        release_@lapack_func@(&eigh_params);
    }
}
/** end repeat **/
static void
@TYPE@_eighlo(char **args, npy_intp *dimensions, npy_intp *steps, void *NPY_UNUSED(func))
{
    @TYPE@_eigh_wrapper('V', 'L', args, dimensions, steps);
}

static void
@TYPE@_eighup(char **args, npy_intp *dimensions, npy_intp *steps, void* NPY_UNUSED(func))
{
    @TYPE@_eigh_wrapper('V', 'U', args, dimensions, steps);
}

static void
@TYPE@_eigvalshlo(char **args, npy_intp *dimensions, npy_intp *steps, void* NPY_UNUSED(func))
{
    @TYPE@_eigh_wrapper('N', 'L', args, dimensions, steps);
}

static void
@TYPE@_eigvalshup(char **args, npy_intp *dimensions, npy_intp *steps, void* NPY_UNUSED(func))
{
    @TYPE@_eigh_wrapper('N', 'U', args, dimensions, steps);
}
/**end repeat**/


static void *array_of_nulls[] = {
    (void *)NULL,
    (void *)NULL,
    (void *)NULL,
    (void *)NULL,

    (void *)NULL,
    (void *)NULL,
    (void *)NULL,
    (void *)NULL,

    (void *)NULL,
    (void *)NULL,
    (void *)NULL,
    (void *)NULL,

    (void *)NULL,
    (void *)NULL,
    (void *)NULL,
    (void *)NULL
};

#define ARRAY_NAME(NAME) NAME ## _funcs
#define FUNCS_REAL(NAME) FLOAT_ ## NAME, DOUBLE_ ## NAME
#define FUNCS_REAL_COMPLEX(NAME) FUNCS_REAL(NAME), CFLOAT_ ## NAME, CDOUBLE_ ## NAME
#define GUFUNC_FUNC_ARRAY_REAL(NAME) static PyUFuncGenericFunction \
    ARRAY_NAME(NAME)[] = { FUNCS_REAL(NAME) }
#define GUFUNC_FUNC_ARRAY_REAL_COMPLEX(NAME) static PyUFuncGenericFunction \
    ARRAY_NAME(NAME)[] = { FUNCS_REAL_COMPLEX(NAME) }


GUFUNC_FUNC_ARRAY_REAL(inner1d);
GUFUNC_FUNC_ARRAY_REAL(innerwt);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(matrix_multiply);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(slogdet);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(det);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eighlo);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eighup);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eigvalshlo);
GUFUNC_FUNC_ARRAY_REAL_COMPLEX(eigvalshup);

static char equal_2_types[] = {
    NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_CFLOAT,
    NPY_CDOUBLE, NPY_CDOUBLE
};

static char equal_3_types[] = {
    NPY_FLOAT, NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_CFLOAT, NPY_CFLOAT,
    NPY_CDOUBLE, NPY_CDOUBLE, NPY_CDOUBLE 
};

/* second result is logdet, that will always be a REAL */
static char slogdet_types[] = {
    NPY_FLOAT, NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_CFLOAT, NPY_FLOAT,
    NPY_CDOUBLE, NPY_CDOUBLE, NPY_DOUBLE 
};

static char eig_types[] = {
    NPY_FLOAT, NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_FLOAT, NPY_CFLOAT,
    NPY_CDOUBLE, NPY_DOUBLE, NPY_CDOUBLE 
};

static char eigvals_types[] = {
    NPY_FLOAT, NPY_FLOAT,
    NPY_DOUBLE, NPY_DOUBLE,
    NPY_CFLOAT, NPY_FLOAT,
    NPY_CDOUBLE, NPY_DOUBLE
};

typedef struct gufunc_descriptor_struct {
    char *name;
    char *signature;
    char *doc;
    int ntypes;
    int nin;
    int nout;
    PyUFuncGenericFunction *funcs;
    char *types;
} GUFUNC_DESCRIPTOR_t;

GUFUNC_DESCRIPTOR_t gufunc_descriptors [] = {
    {
        "inner1d",
        "(i),(i)->()",
        "inner on the last dimension and broadcast on the rest \n"\
        "    \"(i),(i)->()\" \n",
        2, 2, 1,
        inner1d_funcs,
        equal_2_types
    },

    {
        "innerwt",
        "(i),(i),(i)->()",
        "inner on the last dimension using 3 operands and broadcast on the rest \n"\
        "    \"(i),(i),(i)->()\" \n",
        2, 3, 1,
        innerwt_funcs,
        equal_3_types
    },

    {
        "matrix_multiply",
        "(m,p),(p,n)->(m,n)",
        "dot on the last two dimensions and broadcast on the rest \n"\
        "    \"(m,p),(p,n)->(m,n)\" \n",
        4, 2, 1,
        matrix_multiply_funcs,
        equal_3_types
    },

    {
        "slogdet",
        "(m,n)->(),()", /* should be (m,m)->(),() ... but the gufunc harness needs fixing */
        "slogdet on the last two dimensions and broadcast on the rest. \n"\
        "Results in two arrays, one with sign and the other with log of the determinants. \n"\
        "    \"(m,n)->(),()\" \n",
        4, 1, 2,
        slogdet_funcs,
        slogdet_types
    },

    {
        "det",
        "(m,n)->()", /* should be (m,m)->(),() ... but the gufunc harness needs fixing */
        "det of the last two dimensions and broadcast on the rest. \n"\
        "    \"(m,n)->()\" \n",
        4, 1, 1,
        det_funcs,
        equal_2_types
    },
    {
        "eigh_lo",
        "(m,n)->(m),(m,n)", /* should be (m,m)->(m),(m,m) ... but the gufunc harness needs fixing */
        "eigh on the last two dimension and broadcast to the rest, usine lower triangle \n"\
        "Results in a vector of eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m),(m,m)\" \n",
        4, 1, 2,
        eighlo_funcs,
        eig_types
    },
    {
        "eigh_up",
        "(m,n)->(m),(m,n)", /* should be (m,m)->(m),(m,m) ... but the gufunc harness needs fixing */
        "eigh on the last two dimension and broadcast to the rest, using upper triangle. \n"\
        "Results in a vector of eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m),(m,m)\" \n",
        4, 1, 2,
        eighup_funcs,
        eig_types
    },
    {
        "eigvalsh_lo",
        "(m,n)->(m)", /* should be (m,m)->(m), ... but the gufunc harness needs fixing */
        "eigh on the last two dimension and broadcast to the rest, using lower triangle. \n"\
        "Results in a vector of eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m)\" \n",
        4, 1, 1,
        eigvalshlo_funcs,
        eigvals_types
    },
    {
        "eigvalsh_up",
        "(m,n)->(m)", /* should be (m,m)->(m) ... but the gufunc harness needs fixing */
        "eigvalsh on the last two dimension and broadcast to the rest, using upper triangle. \n"\
        "Results in a vector of eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m)\" \n",
        4, 1, 1,
        eigvalshup_funcs,
        eigvals_types
    }
#if 0
    {
        "eig",
        "(m,m)->(m),(m,m)",
        "eig on the last two dimension and broadcast to the rest. \n"\
        "Results in a vector of eigenvalues and a matrix with the eigenvectors. \n"\
        "    \"(m,m)->(m),(m,m)\" \n",
        4, 1, 2,
        eig_funcs,
        equal_3_types
    },
    {
        "eigvalsh",
        "(m,m)->(m)",
        "eigvalsh on the last two dimension and broadcast to the rest. \n"\
        "Results in a vector of eigenvalues. \n"\
        "    \"(m,m)->(m),(m,m)\" \n",
        4, 1, 1,
        eigvalsh_funcs,
        equal_2_types
    },
    {
        "eigvals",
        "(m,m)->(m)",
        "eigvals on the last two dimension and broadcast to the rest. \n"\
        "Results in a vector of eigenvalues. \n"\
        "    \"(m,m)->(m),(m,m)\" \n",
        4, 1, 1,
        eigvals_funcs,
        eigvals_types
    },
#endif
};

static void
addUfuncs(PyObject *dictionary) {
    PyObject *f;
    int i;
    const int gufunc_count = sizeof(gufunc_descriptors)/sizeof(gufunc_descriptors[0]);

    for (i=0; i < gufunc_count; i++) {
        GUFUNC_DESCRIPTOR_t* d = &gufunc_descriptors[i];
        f = PyUFunc_FromFuncAndDataAndSignature(d->funcs, 
                                                array_of_nulls,
                                                d->types,
                                                d->ntypes,
                                                d->nin,
                                                d->nout,
                                                PyUFunc_None,
                                                d->name,
                                                d->doc,
                                                0,
                                                d->signature);
        PyDict_SetItemString(dictionary, d->name, f);
        /* dump_ufunc_object((PyUFuncObject*) f); */
        Py_DECREF(f);                                               
    }
}

/*
    End of auto-generated code.
*/

static PyObject *
UMath_Tests_test_signature(PyObject *NPY_UNUSED(dummy), PyObject *args)
{
    int nin, nout;
    PyObject *signature, *sig_str;
    PyObject *f;
    int core_enabled;

    if (!PyArg_ParseTuple(args, "iiO", &nin, &nout, &signature)) return NULL;


    if (PyString_Check(signature)) {
        sig_str = signature;
    } else if (PyUnicode_Check(signature)) {
        sig_str = PyUnicode_AsUTF8String(signature);
    } else {
        PyErr_SetString(PyExc_ValueError, "signature should be a string");
        return NULL;
    }

    f = PyUFunc_FromFuncAndDataAndSignature(NULL, NULL, NULL,
        0, nin, nout, PyUFunc_None, "no name",
        "doc:none",
        1, PyString_AS_STRING(sig_str));
    if (sig_str != signature) {
        Py_DECREF(sig_str);
    }
    if (f == NULL) return NULL;
    core_enabled = ((PyUFuncObject*)f)->core_enabled;
    Py_DECREF(f);
    return Py_BuildValue("i", core_enabled);
}

static PyMethodDef UMath_LinAlgMethods[] = {
    {"test_signature",  UMath_Tests_test_signature, METH_VARARGS,
     "Test signature parsing of ufunc. \n"
     "Arguments: nin nout signature \n"
     "If fails, it returns NULL. Otherwise it will returns 0 for scalar ufunc "
     "and 1 for generalized ufunc. \n",
     },
    {NULL, NULL, 0, NULL}        /* Sentinel */
};

#if defined(NPY_PY3K)
static struct PyModuleDef moduledef = {
        PyModuleDef_HEAD_INIT,
        umath_linalg_module_name,
        NULL,
        -1,
        UMath_TestsMethods,
        NULL,
        NULL,
        NULL,
        NULL
};
#endif

#if defined(NPY_PY3K)
#define RETVAL m
PyObject *PyInit_umath_linalg(void)
#else
#define RETVAL
PyMODINIT_FUNC
initumath_linalg(void)
#endif
{
    PyObject *m;
    PyObject *d;
    PyObject *version;

#if defined(NPY_PY3K)
    m = PyModule_Create(&moduledef);
#else
    m = Py_InitModule(umath_linalg_module_name, UMath_LinAlgMethods);
#endif
    if (m == NULL)
        return RETVAL;

    import_array();
    import_ufunc();

    d = PyModule_GetDict(m);

    version = PyString_FromString("0.1");
    PyDict_SetItemString(d, "__version__", version);
    Py_DECREF(version);

    /* Load the ufunc operators into the module's namespace */
    addUfuncs(d);
    
    if (PyErr_Occurred()) {
        PyErr_SetString(PyExc_RuntimeError,
                        "cannot load umath_tests module.");
    }

    return RETVAL;
}
